\newcommand{\UseWhiteBackground}{1}  % Copy this to have a white document
\input{../preambule.tex}

\title{Between decideable logics: $\mathbf{\omega}$-automata and infinite games}
\author{Diego Dorn}

\renewcommand{\todo}[1]{}

\newcommand{\infiniteWords}{\infseq{(\IB^n)}}
\newcommand{\Sing}{\mathrm{Sing}}
\newcommand{\Succ}{\mathrm{Succ}}

\newlength{\LETTERheight}
\AtBeginDocument{\settoheight{\LETTERheight}{I}}
\newcommand{\pathto}[1]{\mathrel{\overset{#1}{
\raisebox{0.24\LETTERheight}{\tikz \draw [->,
line join=round,
decorate, decoration={
    zigzag,
    segment length=4,
    amplitude=.9,
    post=lineto,
    post length=2pt
}] (0,0) -- (0.5,0);}
}}}
\newcommand{\inlinesafra}[1]{
    \pbox[c]{5cm}{
    \begin{forest}safra,
        [#1]
    \end{forest}
    }
}
\newcommand{\boite}[1]{\ifthenelse{\isempty{#1}}%
    {\Square}%
    {[#1]\,}%
}
\newcommand{\diam}[1]{\ifthenelse{\isempty{#1}}%
    {\Diamond}%
    {\langle#1\rangle\,}%
}
\newcommand{\Neigh}[3][]{\mathrm{Neigh}\ifthenelse{\isempty{#1}}{%
    \ifthenelse{\isempty{#2}}{%
        (#3)%
    }{%
        _{#2}(#3)%
    }
}{%
    ^{#1}_{#2}(#3)%
}}

\newcommand{\Meaning}[1]{\llbracket#1\rrbracket}
\newcommand{\Attacker}{\textsf{Attacker}\xspace}
\newcommand{\Defender}{\textsf{Defender}\xspace}
\newcommand{\Verifier}{\textsf{Verifier}\xspace}
\newcommand{\Falsifier}{\textsf{Falsifier}\xspace}
\newcommand{\AlternatingDepth}{\mathrm{adepth}}

\newcommand{\State}[1]{%\scalebox{0.5}{
\begin{tikzpicture}[baseline=(O.base), minimum size=0.7cm, inner sep=0pt]
    \node[draw,circle] (O) {\(#1\)};
\end{tikzpicture}%}
\xspace}

\newcommand{\spacedAutomata}[1]{\begin{center}
\begin{tikzpicture}[automata, node distance=90pt]
#1
\end{tikzpicture}
\end{center}}

\forestset{
    safra/.style={
        for tree={
            draw,
            rectangle split,
            rectangle split parts=2,
            rectangle split horizontal,
            % rectangle split part fill={red, white},
            fill=white,
            rounded corners,
            draw=black,
            anchor=north,
        },
    },
    formula/.style={
        for tree={
            edge={->},
            draw,
            circle,
            minimum size=1cm,
            math content,
            anchor=center,
        }
    }
}
\newcommand{\safranode}[2]{\nodepart{one}#1\nodepart{two}#2}

\tikzset{
    safrastate/.style={
        thin,circle,fill=ghostwhite,
    },
    edge0/.style={
        ->,
        atomictangerine,
        ultra thick,
        every node/.style={
            draw, circle,
            text=black,
            fill=white,
        }
    },
    edge1/.style={
        ->,
        bondiblue,
        ultra thick,
        every node/.style={
            draw, circle,
            text=black,
            fill=white,
        },
    },
    priority odd/.style={
        regular polygon,
        regular polygon sides=4,
        fill=awesome!15,
        draw=awesome!50,
        minimum size=0.2cm,
        inner sep=0.5pt,
    },
    priority even/.style={
        regular polygon,
        regular polygon sides=4,
        fill=airforceblue!15,
        draw=airforceblue!50,
        minimum size=0.2cm,
        inner sep=0.5pt,
    },
}


\begin{document}

\input{first_page.tex}


% \listoftodos[Remaining to be done]
% \newpage

% \setcounter{section}{-1}
\section*{Introduction}

In the world of logics, it is
quite a surprising fact when one of them is decidable.
It is even more remarkable when such decidable logic
is expressive enough to be used in real world applications,
and not only as a toy for logicians.
We present here two decidable logics,
\textit{monadic second order logic} over infinite strings
and \textit{$\mu$-calculus}.
Those two logics are tightly related to each other
and can be studied by means of infinite games of perfect information
between two player and also automata that read infinite words.

The results developped here show the potential of those logic
for tools of formal verification: they can express a lot of properties
that we would like to formally prove on our computer programs,
and since they are decidable, we can write complete automated tools
to verify that those properties hold. This model checking
of $\mu$-calculus can be done in quasipolynomial time,
but it is still an open question if it is possible to do it in polynomial time.

% Monadic second order logic is an extension of first order
% logic in which one is also allowed to quantify over subsets
% of the domain. It turns out that this logic, on infinte words
% is as expressive as the notion of Büchi automata.
% We study the more general notion of \w-automata in order
% to show decidability and also algorithmic properties of this logic.
% In particular, we study the Safra construction, whic

\todo{add contents section}

\tableofcontents


\clearpage
\section*{Conventions}

\paragraph{Ordinals}
We use \N to denote the set of integers, which contains 0.
It is the same set as \w, the first infinite ordinal.
We use them interchangebly, but \w makes focus on the order
whereas \N is used more as a set.

\paragraph{Sequences} A sequence, or \w-word, on a set $X$ is a function
from \w to $X$. We denote the set of sequences on $X$ as $\infseq{X}$
and given $x \in X$ and an integer $n \in \N$, we write $x_n$ instead of $x(n)$ to have less parentheses.

A finite sequence, or word, on a set $X$ is a function $x: \set{0, ..., n} \to X$,
where $n$ is the length of the finite sequence, also denoted $\abs{x}$.
The set of finite sequences on $X$ is $\finiteseq{X}$.
Given two finite sequences $s$ and $t$, we write $s \concat t \in \finiteseq{X}$
for the concatenation of the two finite sequences.

Given a sequence $x$, finite or infinite, and an integer $n \in \N$,
we write $x \restr n$ for the sequence $x$ restricted to the first $n$ elements.
If $n < m$, we write $x_{n..m}$ for the subsequence of $x$ that starts at
position $n$ and ends at position $m$, both included.

\paragraph{Sets}
An alphabet is any finite set, whose elements are called letters or symbols.
Given a set $X$, $\Pp(X)$ is the power set of $X$, which contains every subset of $X$.
We use the symbol $\subseteq$ for the non-strict inclusion of one set to the other
and $\subsetneq$ for the strict inclusion.

\paragraph{Formulas}
Formulas are trees, where each node contains a symbol, variable, logical connector,
quantifer or term. Given a formula \p and two terms $x$ and $y$,
we write $\phi[x := y]$ for the formula where every occurence of $x$ is replaced by $y$.

\clearpage

\section{Automata on infinite words}
\subsection{Three kinds of automata}

In the following sections
we will make good use of automata that read infinite words.
Those automata are very similar to the more common
finite state machines but differ in how they accept
or reject their inputs.

\begin{definition}
    Let $\Sigma$ be a finite alphabet.
    An \emph{\w-automaton} $\Aa = (Q, \Sigma, \delta, q_0, Acc)$
    consists of:
    \begin{itemize}
        \item a finite set of states, $Q$;
        \item a finite alphapet, $\Sigma$;
        \item a transition function $\delta : Q \times \Sigma \to \Pp(Q)$;
        \item an initial state $q_0 \in Q$;
        \item a set $Acc \subseteq \infseq{Q}$ of accepting runs.
    \end{itemize}

    A run of the \w-automaton on an input $w \in \infseq\Sigma$
    is any sequence of states $r \in \infseq{Q}$ such that
    $r_0 = q_0$ and for all $n > 0$, $r_n \in \delta(r_{n-1}, w_n)$.
    Such run is \emph{accepting} if it belongs to $Acc$.
    Otherwise, if $r \notin Acc$, it is \emph{rejecting}.

    We say that $\Aa$ accepts the infinite word $w \in \infseq{\Sigma}$
    if there exists an accepting run on $w$.

    An \w-automaton is \emph{deterministic} if for all
    letters $s \in \Sigma$ and each state $q \in Q$,
    there is exactly one transition from $q$ to another state
    when $s$ is read. That is, $\abs{\delta(q, s)} = 1$.
    Otherwise, it is \emph{non-deterministic}.

\end{definition}


This provides a general context in which automata can read infinite
words. However, it is too general because the accepting condition
can be arbitrarily complex and even non-computable.
We will mostly look at three types of accepting conditions:

\begin{multicols}{2}
\begin{itemize}
    \item Buchi conditions
    \item Muller conditions
    \item Parity conditions
    % \item Rabin conditions
\end{itemize}
\end{multicols}

Each of these conditions defines the $Acc$ set
from simpler data and rely on the set of states that
a run passes through infinitely many times.
To make the notation more convenient, given a sequence
$w$, we write $\Inf(w)$ to denote the
elements of $w$ that appear at infinitely many indices in $w$.

\begin{definition}
    Let $w \in \infseq{X}$ be sequence on any set $X$.
    We define $\Inf(w) \subseteq X$ as
    \[
        \Inf(w) := \setst{x \in X}{
            \forall N \in \N~
            \exists n > N~
            w_n = x
        }
    \]
\end{definition}

\begin{definition}[Acceptance conditions]
    An \w-automaton has a \emph{Büchi acceptance condition}
    if for some set of states $F \subseteq Q$,
    a run passes through $F$ infinitely many times:
    \[
        Acc := \setst{
            r \in \infseq{Q}
        }{
            \Inf(r) \cap F \neq \emptyset
        }.
    \]

    An \w-automaton has a \emph{Muller acceptance condition}
    if for some collection of subsets of the states $F \subseteq \Pp(Q)$,
    a run is accepted if and only if the set of states that
    are visited infinitely many times belongs to $F$.
    \[
        Acc := \setst{
            r \in \infseq{Q}
        }{
            \Inf(r) \in F
        }.
    \]

    An \w-automaton has a \emph{parity acceptance condition}
    if for some function $p : Q \to \N$ called the priority function,
    a run is accepted if and only if the state with the lowest priority
    that is visited infinitely many times belongs has an even priority:
    \[
        Acc := \setst{
            r \in \infseq{Q}
        }{
            \min_{q \in \Inf(r)} p(q) \text{ is even}
        }.
    \]
\end{definition}

\begin{remark}
    As a shorthand, we will say ``a Büchi automaton''
    instead of ``an \w-automaton with a Büchi acceptance condition'',
    and similarly for each other acceptance conditions.

    Note that by default we consider non-deterministic automata,
    so we will mention every time we consider deterministic
    automata.
\end{remark}

\begin{definition}
    Let $\Aa$ be an \w-automaton on an alphabet $\Sigma$.
    The \emph{language} of $\Aa$, denoted $\Ll(\Aa)$,
    is the set of all infinite words accepted by $\Aa$.
    \[
        \Ll(\Aa) := \setst{w \in \infseq{\Sigma}}{\Aa \text{ accepts } w}
    \]

    We say that a \w-language $L \subseteq \infseq{\Sigma}$ is
    \emph{Büchi-definable} if there is a Büchi automaton $\Aa$
    whose language is $L$,  that is, $\Ll(\Aa) = L$
    and similarly for the other acceptance conditions.
\end{definition}


\begin{examples}
    The following automata all recognise the same language,
    which consist of words made of \texttt{0}s and \texttt{1}s
    that contain infinitely many times
    the letter \texttt{1}, but only finitely many time the sequence \texttt{11}.

    To facilitate the reading of the automata, we always use orange arrows for
    transitions when reading the letter \verb|0|, and blue arrows for the letter \verb|1|,
    and we may sometimes omit the labels. The initial state is denoted by
    an incoming black arrow and for Büchi automata, accepting states are double circled.

    \begin{center}
        \input{fig/buchi-1-no-11.tex}
    \end{center}

    The above automaton is a Büchi automaton, so it accepts a word if and only if
    there is a way to follow the arrows that passes infinitly many times through the state C,
    which is the only accepting state. One can notice that there is no path from C to A,
    so any infinite run that passez through C just alternates between B and C.
    Since there is only one arrow reaching C, with a \texttt{1} on it,
    any word accepted must have infinitely many \texttt{1}s. We also notice
    that when cycling between states B and C, it is impossible to have two \texttt{1}s
    in a row, as one would make the transition from B to C, but there is not arrow
    with a \texttt{1} leaving C, and the run would just end. What is the purpose of the
    state A then ? It allows to skip any finite prefix of the input word, where anything could happen
    (for instance some \texttt{11}s).
    Once all the occurences of \texttt{11} have been read, and the tail of the word consists
    only of zeroes and isolated ones, the automaton can transition to B and then C.

    With a deterministic parity automaton, the same language can be recognised
    (in fact, the next section is about showing that the two notions are equivalent).

    \begin{center}
        \begin{tikzpicture}[>=latex',join=bevel,node distance=70bp]
            \node[initial, state] (1) {3};
            \node[state, right of=1] (2) {2};
            \node[state, right of=2] (3) {1};

            \path (1) edge[edge0, loop above] (1)
                    edge[edge1, bend left] node {1} (2)
                (2) edge[edge0, bend left] node {0} (1)
                    edge[edge1, bend left] node {1} (3)
                (3) edge[edge0, bend left=45] (1)
                    edge[edge1, loop above] (3);
        \end{tikzpicture}
    \end{center}

    This parity automaton, with the priorities written on the nodes
    also recognise the language with infinitely many \texttt{1}s,
    but finitely many \texttt{11}s. Indeed, in order for a run
    to be accepted, it the smallest priority visited infinitely many times
    must be even. Here, there is only one even priority, so it must
    visit the middle node infinitely many times, but not the rightmost node.
    However, every time a \texttt{0} is read,
    the automton goes beck to node 3, and every time a \texttt{1} is read,
    it moves towards node 1. So in order to avoid visiting node 1
    infinitely many times, there must be a finite number of \texttt{11}
    in the word. We can also see that if the tail of the word
    contain only zeros, the automaton will stay in state 3, and reject the word,
    so an accepted word must have infinitely many ones.


    A Muller automata that recognise the same language
    is very similar to the parirty automaton, but only the
    definition of the acceptance condition changes.

    \begin{center}
        \begin{tikzpicture}[>=latex',join=bevel,node distance=70bp]
            \node[initial, state] (1) {A};
            \node[state, right of=1] (2) {B};
            \node[state, right of=2] (3) {C};

            \path (1) edge[edge0, loop above] (1)
                    edge[edge1, bend left] node {1} (2)
                (2) edge[edge0, bend left] node {0} (1)
                    edge[edge1, bend left] node {1} (3)
                (3) edge[edge0, bend left=45] (1)
                    edge[edge1, loop above] (3);
        \end{tikzpicture}
    \end{center}

    Here we define the family of accepting states as $\Ff = \bigset{\set{A, B}}$.
    This is mostly an other way of expressing the condition of
    the parity automaton: we want an accepting run to visit
    infinitely many times the two states on the left, and only finitely
    many times the states on the right.
    In general, parity automata are a special case of Muller automata,
    when the family of accepting subsetsets of state can be defined
    by a priority function.

\end{examples}

\begin{lemma}
    Any parity automaton is also a Müller automaton.
\end{lemma}
\begin{proof}
    Let $\Aa = (Q, \Sigma, \delta, q_0, p)$ be parity automaton.
    Its acceptance condition is also a Muller acceptance condition as we can take
    \[
        \Ff = \setst{F \subseteq Q}{\min_{q \in F} ~p(q) \even}
    \]
    which is a Muller condition.
\end{proof}

One might then wonder why we would use parity automata in the first place,
but they have the advantage of being easier to understand for a human brain
because of the more explicit structure of the set of accepting runs.
They are also easier to represent and sometimes easier to reason about,
for instance, they are a bit simpler to convert to Büchi automata than Muller automata are.


\subsection{Equivalences between automata}
The goal of the following section is to show the equivalences
between different notions of \w-automata.
Two kinds of \w-automata, for instance, Muller and parity automata
are equivalent if they can recognise the exact same languages,
that is, a language is Muller-definable if and only if it parity-definable.
We will show the following:

\begin{theorem}
    \label{thm:all-automata-are-the-same}
    Let $L \subseteq \infseq\Sigma$ be a language.
    \[
        \begin{array}{c}
        L \text{ is recognised by a Büchi automaton} \\
        \iff \\
        L \text{ is recognised by a deterministic Muller automaton} \\
        \iff \\
        L \text{ is recognised by a deterministic parity automaton} \\
        \end{array}
    \]

    However, some languages are recognised by the above
    automata that cannot be recognised by any deterministic Büchi automaton.
\end{theorem}

This section will focus on showing all those equivalences,
and provide explicit constructions to convert one kind of automata
into the other.
The contruction to transform a Büchi automaton into a deterministic Muller automaton,
however, is much more complex and will be carried in
it own \autoref{sec:safra}.

\begin{lemma}
    \label{lem:muller-to-parity}
    Let $\Mm$ be a deterministic Muller automaton,
    then there exists a deterministic parity automaton $\Aa$
    such that $\Ll(\Mm) = \Ll(\Aa)$.
\end{lemma}

\begin{proof}
    The proof is carried out in two steps.
    First we assume that $\Mm = (Q, \Sigma, \delta, q_0, \Ff)$
    with $\abs{F} = 1$, that is, there is only one set
    of states that can occur infinitely many times.
    We then show that parity automata are closed under disjunctions
    and conclude that if $\Ff = \set{F_1, F_2, \dots, F_n}$
    we can construct a parity automaton from the automata
    $\Aa_i$ made from $\Mm$ and replacing $\Ff by \set{F_i}$.

    \paragraph*{Case of one accepting subset}
    Let $\Mm = (Q, \Sigma, \delta, q_0, \Ff)$ be a Muller automaton
    with $\Ff = \set{F}$. Let also $F = \set{f_1, f_2, \dots, f_n}$.
    We define $\Aa = (Q', \Sigma, \delta', q'_0, p)$ as follows:
    \begin{itemize}
        \item The set of states is $Q' = Q \times F$.
        \item The initial state is $q'_0 = (q_0, f_0)$.
        \item The priority of a state $(q, f) \in Q'$ is \[
            p\Par[1]{(q, f)} = \begin{cases}
                1 & \tif q \notin F \\
                2 & \tif (q, f) = (f_0, f_0) \\
                3 & \otherwise.
            \end{cases}
        \]
        \item Since the automaton is deterministic, we give the transition
            function as $\delta': Q' \times \Sigma \to Q'$. Let $q \in Q, f_i \in F$
            and $a \in \Sigma$. We set \[
            \delta'\bigparenthesis{(q, f_i), a} = \begin{cases}
                \bigparenthesis{\delta(q, a), f_{i+1}} & \tif q = f_i \andd i < k \\
                \bigparenthesis{\delta(q, a), f_0} & \tif q = f_i \andd i = k \\
                \bigparenthesis{\delta(q, a), f_i} & \otherwise.
            \end{cases}
        \]
    \end{itemize}

    \paragraph{Correctness of the construction}
    Let $w \in \infseq{\Sigma}$ be an \w-word accepted by $\Aa$ and let $r' \in \infseq{Q'}$
    be the corresponding run.
    By the definition of $\delta'$, the run $r \in \infseq{Q}$ of $w$ on $\Mm$
    is exactly the projection of $r'$ on its first coordinate, that is, $r = \pi_1(r')$.
    Since $r'$ is accepted by \Aa, we know that $r'$
    visits finitely many times states of priority 1, which are the
    states in $(Q \setminus F) \times F = \pi^{-1}_1(Q \setminus F)$.
    Therefore $\Inf(\pi_1(r')) \subseteq F$ and equivalently $\Inf(r) \subseteq F$.
    For the other inclusion, we have that $r'$ visits infinitely many
    times the only state of even priority, $(f_0, f_0)$. However,
    every time it does so, the run proceeds into $Q \times \set{f_1}$,
    which can be escaped only when reaching $(f_1, f_1)$,
    and then proceeds to the subset $Q \times \set{f_2}$, and so on.
    Therefore, it has visited every state of the form $(f_i, f_i)$
    before reaching $(f_0, f_0)$ again, and thus $\Inf(r) = \pi_1(r') = F$

    For the reverse implication, assume that $w \in \infseq{\Sigma}$ is accepted by \Mm
    on the run $r \in \infseq{Q}$ and let $r' \in \infseq{Q'}$ be the run in \Aa.
    Since $\Inf(r) = F$ and $\Inf(r') \subseteq \Inf(\pi^{-1}_1(r)) = F \times F$,
    we know that $r'$ visits nodes of priority 1 finitely many times.
    It remains to show that $r'$ visits $(f_0, f_0)$ infinitely many times.
    Let $n$ be an integer. We show that, if $r'_n = (q, f_k)$, for some $k$,
    then there is some $m > n$ such that $r'_m = (f_k, f_k)$.
    Indeed, appart from the transions from $(f_k, f_k)$, the transitions
    inside the subset $Q \times \set{f_k}$ of $Q'$ match exactly those of the
    Muller automaton \Mm. Since in $\Mm$ the run $r$ visits $f_k$,
    it must also be the case in $Q \times \set{f_k}$.
    Finally, this fact shows that every state of the form $(f_k, f_k)$ is
    visited infinitely many times, and therefore $r'$
    visits $(f_0, f_0)$ infinitely many times and accepts $w$.

    \paragraph{Parity automata are closed under disjunctions}
    Let $\Aa_0 = (Q_0, \Sigma, \delta_0, q_0, p_0)$
    and $\Aa_1 = (Q_1, \Sigma, \delta_1, q_1, p_1)$
    be two parity automata.
    We build an automata $\Bb = (Q, \Sigma, \delta, q, p)$
    such that $\Ll(\Bb) = \Ll(\Aa) \cup \Ll(\Aa')$.
    The construction follows the cartesian product of the automata,
    with a specific priority function: \begin{itemize}
        \item The set of states is $Q = Q_0 \times Q_1$.
        \item The initial state is $q = (q_0, q_1)$.
        \item The transition function is $\delta = (\delta_0,  \delta_1)$,
            that is, for any state $(s, s') \in Q$, and any symbol $a \in \Sigma$,
            \[
                \delta((s, s'), a) =
                    \bigparenthesis{
                        \delta_0(s, a),
                        \delta_1(s', a)
                    }
            \]
        \item The priority function $p: (Q_0 \times Q_1) \to \N$
            is any function that verify those three conditions:
            \begin{enumerate}
                \item it assigns to each pair $(s, s') \in Q$
                    an even number if and only if either $p(s)$ or $p(s')$ is even.
                \item for each $t \in Q_0$, $p(s, s') < p(t, s')$
                    if and only if $p_0(s) < p_0(t)$ so that the order is preserved.
                \item symetrically, for each $t \in Q_1$, $p(s, s') < p(s, t)$
                    if and only if $p_1(s') < p_1(t)$.
            \end{enumerate}
            To give an explit function, let $N := 2 \cdot \max_{q \in Q_1} p_1(q) + 2$ and $(s, s') \in Q$.
            We set
            \[
                p(s, s') = \begin{cases}
                    N \cdot p_0(s) + p_1(s') & \tif p_0(s) \odd \\
                    N \cdot p_0(s) + 2 \cdot p_1(s') & \tif p_0(s) \even
                \end{cases}
            \]
    \end{itemize}

    \paragraph*{Correctness of the construction}
    Let $w \in \infseq{\Sigma}$ be an \w-word and run $r, r_0$ and $r_1$
    be the runs on $\Bb, \Aa_0$ and $\Aa_1$ respectively.
    By construction, the two coordinates of the run $r$ are the runs $r_0$ and $r_1$.

    The minimal priority of $\Inf(r)$ is obtained
    on some state $(s, s') \in Q$. By the first condition
    of the priority function, $p(s, s')$ is even if and only if
    either $p_0(s)$ or $p_1(s')$ is even
    and by condition 2 and 3, $s$ (resp. $s'$) is also
    a state of $\Inf(r_0)$ (resp. $\Inf(r_1)$) with minimal priority.
    Therefore, $r$ is accepted if and only if $r_0$ or $r_1$ is accepted,
    and $w \in \Ll(\Aa_0) \cup \Ll(\Aa_1)$.

\end{proof}

\begin{example}
    We illustrate the construction to convert a Müller automaton
    with only one accepting subset into a parity automaton
    with the now familiar automaton to recognise words with infinitely many \texttt{1}s
    but finitely many \texttt{11}s.
    We recall that this Muller automaton is
    \begin{center}
        \begin{tikzpicture}[>=latex',join=bevel,node distance=70bp]
            \node[initial, state] (1) {A};
            \node[state, right of=1] (2) {B};
            \node[state, right of=2] (3) {C};

            \path (1) edge[edge0, loop above] (1)
                    edge[edge1, bend left] node {1} (2)
                (2) edge[edge0, bend left] node {0} (1)
                    edge[edge1, bend left] node {1} (3)
                (3) edge[edge0, bend left=45] (1)
                    edge[edge1, loop above] (3);
        \end{tikzpicture}
    \end{center}
    With acceptance condition $\Ff = \set{\set{A, B}}$. The resulting parity automaton
    must therefore have six states, and two copies of the Muller automaton.
    One of this copy will have the transitions going out of the A node modified
    to point the the second copy, and the B node of the second copy will have its transitions
    modified to point to the first copy. Copies of C have priority 1, as C does not belong to
    the accepting condition, and we set the only node with priority 2 to be the A node in the
    first copy. Every other node has a priority of three.

    \begin{center}
        \begin{tikzpicture}[>=latex',join=bevel,node distance=70bp]
            % States of the first copy
            \node[fill=white,initial, state] (AA) {2};
            \node[fill=white,state, right of=AA] (BA) {3};
            \node[fill=white,state, right of=BA] (CA) {1};

            % States of the second copy
            \node[fill=white,state] (AB) at (0, -4) {3};
            \node[fill=white,state, right of=AB] (BB) {3};
            \node[fill=white,state, right of=BB] (CB) {1};

            \path (AA) edge[edge0, bend right] node {0} (AB)
                       edge[edge1,bend left=15] node {1} (BB)
                  (BA) edge[edge0, ] (AA)
                       edge[edge1, ] (CA)
                  (CA) edge[edge0, bend left] (AA)
                       edge[edge1, loop above] (CA);

            \path (AB) edge[edge0, loop below] (AB)
                       edge[edge1, ] (BB)
                  (BB) edge[edge0, bend left=15] node {0} (AA)
                       edge[edge1, ] node {1} (CA)
                  (CB) edge[edge0, bend left] (AB)
                       edge[edge1, loop above] (CB);

            % \node[priority even] at ($(AA.north east) + (0.07, 0.07)$) {2};
            % \node[priority odd]  at ($(BA.north east) + (0.07, 0.07)$) {3};
            % \node[priority odd]  at ($(CA.north east) + (0.07, 0.07)$) {1};
            % \node[priority odd]  at ($(AB.north east) + (0.07, 0.07)$) {3};
            % \node[priority odd]  at ($(BB.north east) + (0.07, 0.07)$) {3};
            % \node[priority odd]  at ($(CB.north east) + (0.07, 0.07)$) {1};

            \begin{scope}[on background layer]
                \draw[awesome,fill=awesome!5] ($(AA) - (1.5, 1.5)$) rectangle ($(CA) + (1.5, 1.5)$);
                \draw[airforceblue,fill=airforceblue!5] ($(AB) - (1.5, 1.5)$) rectangle ($(CB) + (1.5, 1.5)$);
            \end{scope}

            \node[awesome,anchor=north west] at ($(AA) + (-1.5, 1.5)$) {Copy of A};
            \node[airforceblue,anchor=south east] at ($(CB) + (1.5, -1.5)$) {Copy of B};

            \node[gray] at ($(AA) + (0, 2)$) {A};
            \node[gray] at ($(BA) + (0, 2)$) {B};
            \node[gray] at ($(CA) + (0, 2)$) {C};
        \end{tikzpicture}
    \end{center}

We can notice in this example that even if it uses the same set of priorities $\set{1, 2, 3}$,
as the parity automaton we have already constructed, the resulting automaton is more complex.
A few states, however, are not reachable at all from the start (BA and CB), but this is just
what happens to be in this specific example.

In the next lemma, we prove the second implication, that is, we can convert a deterministic
parity automaton into Büchi automaton.


\end{example}

\begin{lemma}
    Let $\Aa$ be a deterministic parity automaton,
    then there exists a Büchi automaton $\Bb$
    such that $\Ll(\Aa) = \Ll(\Bb)$.
\end{lemma}
\begin{proof}
    Given $\Aa = (Q, \Sigma, \delta, q_0, p)$ a parity automaton,
    we build a Büchi automaton $\Bb = (Q', \Sigma, \delta', q'_0, F)$ that recognises the same language.
    Let $Q_i$ be the states of $\Aa$ of priority $i$
    and $Q_{\geq i} := \setst{q \in Q}{p(q) \geq i}$ the states of $\Aa$ of priority greater than $i$.
    We set \begin{itemize}
        \item The set of states of \Bb is the disjoint union of the $Q_{\geq i}$, for all even $i$, plus one
        copy of $Q$: \[
                Q' = Q \sqcup \bigsqcup_{i \even} Q_{\geq i} =
                Q \sqcup \bigsetst{(q, i) \in Q \times \N}{p(q) \geq i \wedge i \even}
            \]
        \item The initial state is $q_0' = q_0 \in Q'$.
        \item The accepting states of \Bb are the states of priority $i$ in the copy of $Q_{\geq i}$:
        \[
            F = \bigsqcup_{i \even} Q_i = \setst{(q, i) \in Q'}{p(q) = i}
        \]
        \item In each of the $Q_{\geq i}$,
            the transition function is the same as in $\Aa$,
            and the transitions from the copy of $Q$ are the same as in $\Aa$ but
            the automaton can also decide to move to one of the $Q_{\geq i}$.
            So for all all $q \in Q, i \in \N$ and $s \in \Sigma$,
            \[
                \delta'(q, s) = \delta(q, s) \cup \bigcup_{i \even} (\delta(q, s) \cap Q_{\geq i})\times \set{i}
                \] and \[
                \delta'((q, i), s) = \bigparenthesis{\delta(q, s) \cap Q_{\geq i}} \times \set{i}
            \]
    \end{itemize}

    \paragraph*{Correctness of the construction} Let $w \in \Ll(\Aa)$ be and $r \in \infseq{Q}$
    be the corresponding accepting run. Let $p_{min}$ be the minimum priority
    that appears infinitely many times
    in $r$ and let $N = \min \setst{n \in \N}{\forall k \geq n, p(r_k) \geq p_{min}}$
    be the time from which the run never visit a state with a priority lower than $p_{min}$.
    Then the run $q := r\restr{N-1} \concat (r_N, p_{min}) \concat (r_{N+1}, p_{min}) \concat \dots$
    is an accepting run in \Bb.

\end{proof}

\begin{example}
    In order to illustrate this construction, we will convert the complement of our
    favourite parity automaton into a Büchi automaton.

    \begin{center}
        \begin{tikzpicture}[>=latex',join=bevel,node distance=70bp]
            \node[initial, state] (1) {2};
            \node[state, right of=1] (2) {1};
            \node[state, right of=2] (3) {0};

            \path (1) edge[edge0, loop above] (1)
                    edge[edge1, bend left] node {1} (2)
                (2) edge[edge0, bend left] node {0} (1)
                    edge[edge1, bend left] node {1} (3)
                (3) edge[edge0, bend left=45] (1)
                    edge[edge1, loop above] (3);
        \end{tikzpicture}
    \end{center}

    This automaton accepts words which if they have infinitely many \texttt{1}s,
    then they have infinitely many \texttt{11}s.
    The automaton can accept words in two different ways, either
    the minimal priority occurring infinitely many times is 2 or 0.
    If it is 2, there are finitely many ones, and the tail of the word
    is only zeros. If it is 0, then there are infinitely many \texttt{11}s.

    With our construction, we name the nodes with their priority, as no two nodes
    have the same priority. We have $Q_{\leq 0} = Q = \set{0, 1, 2}$ and
    $Q_{\geq 2} = \set{2}$, so the Büchi automaton should have 7 states.

    \begin{center}
        \begin{tikzpicture}[>=latex',join=bevel,node distance=70bp]
            % Copy Q
            \node[state, initial] (n2) {2};
            \node[state, right of=n2] (n1) {1};
            \node[state, right of=n1] (n0) {0};

            \path (n2) edge[edge0, loop left] (n2)
                    edge[edge1, bend left] (n1)
                (n1) edge[edge0, bend left] (n2)
                    edge[edge1, bend left] (n0)
                (n0) edge[edge0, bend right=45] (n2)
                    edge[edge1, loop right] (n0);

            % Copy Q0

            \node[state] (n20) at (0, -4) {2};
            \node[state, right of=n20] (n10) {1};
            \node[state, accepting, right of=n10] (n00) {0};

            \path (n20) edge[edge0, loop left] (n20)
                    edge[edge1, bend left] (n10)
                (n10) edge[edge0, bend left] (n20)
                    edge[edge1, bend left] (n00)
                (n00) edge[edge0, bend left=45] (n20)
                    edge[edge1, loop right] (n00);

            % Copy Q2
            \node[state, accepting] (n22) at (0, 4) {2};
            \path (n22) edge[edge0, loop left] (n22);

            % Edges between copies
            \path (n2) edge[edge0] (n22)
                    edge[edge0] (n20)
                    edge[edge1] (n10)
                (n1) edge[edge0,out=255,in=70] (n20)
                    edge[edge1] (n00)
                (n0) edge[edge0] (n00)
                    edge[edge1,out=240,in=50] (n20)
            ;

            \begin{scope}[on background layer]
                \draw[airforceblue,fill=airforceblue!5] ($(n2) - (1.5, 1.5)$) rectangle ($(n0) + (1.5, 1.5)$);
                \draw[airforceblue,fill=airforceblue!5] ($(n20) - (1.5, 1.5)$) rectangle ($(n00) + (1.5, 1.5)$);
                \draw[airforceblue,fill=airforceblue!5] ($(n22) - (1.5, 1.5)$) rectangle ($(n0) + (1.5, 5.5)$);
            \end{scope}

            \node[airforceblue,anchor=south west] at ($(n20) - (1.5, 1.5)$) {$Q_{\geq 0}$};
            \node[airforceblue,anchor=south west] at ($(n2) - (1.5, 1.5)$) {$Q$};
            \node[airforceblue,anchor=south west] at ($(n22) - (1.5, 1.5)$) {$Q_{\geq 2}$};
        \end{tikzpicture}
    \end{center}

    Note that the number in the states do not have any specific meaning, they are only reminder
    of which node from the original automaton they come from.

\end{example}

\todo{Show that the \borelpi{2} automton cannot be made with det Buchi}

\subsection{The Safra construction}
\label{sec:safra}

There is one equivalence between automata that we did not prove
in the last section: every language that is recognised by a
non-deterministic Büchi automaton can be recognised by a
deterministic Muller automaton. This result concludes
the proof of \autoref{thm:all-automata-are-the-same} and
is the most important result that we will use in the sequel.
Indeed, it allows us to complement non-deterministic Büchi automata
which are very hard to complement otherwise (as is usually the case with non-deterministic automata).
The proof is also quite interesting by itself and makes use of
Safra trees.

\begin{definition}
    Let $Q$ be any finite set.
    A \emph{Safra tree} on $Q$ is a finite tree
    whose children are ordered and each node has:
    \begin{itemize}
        \item a name, $n \in \set{0, \dots, 2\abs{Q}}$
        \item a label, $l \subseteq Q$
        \item an optional marker $!$
    \end{itemize}
    and satisfies the following constraints:
    \begin{itemize}
        \item Every node has a distinct name.
        \item No node can have a label of $\emptyset$, except the root.
        \item The label of a node is a subset of the label of its parent.
        \item Labels of siblings node are disjoint.
        \item The union of labels of siblings node is a proper subset of the label of their parent.
    \end{itemize}
\end{definition}

The following trees are Safra trees on $Q = \set{A, B, C, D}$, where the name is written
on the left and the label on the right:

\begin{center}
\begin{forest}safra,
[,phantom, s sep = 1cm
    [\safranode{0}{$\emptyset$}]
    [\safranode{0}{AB}
        [\safranode{1}{B}
        ]]
    [\safranode{3}{ABC !}
        [\safranode{2}{A !}]
        [\safranode{4}{B}]
    ]
    [\safranode{0}{ABCD}
        [\safranode{2}{C}]
        [\safranode{3}{AD !}
            [\safranode{4}{D}]
        ]
    ]
]
\end{forest}
\end{center}

We can also have trees that are \emph{not} Safra trees.
For instance, each of the following trees violates exactly one of the
conditions of a Safra tree:


\begin{center}
\begin{forest}safra,
[,phantom, s sep = 1cm
    [\safranode{0}{ABCD}
        [\safranode{2}{$\emptyset$}]
        [\safranode{3}{AD !}
            [\safranode{4}{D}]
        ]
    ]
    [\safranode{0}{AB}
        [\safranode{0}{B}
        ]]
    [\safranode{0}{AB}
        [\safranode{1}{AB}
        ]]
    [\safranode{0}{AB}
        [\safranode{1}{C}
        ]]
    [\safranode{3}{ABC !}
        [\safranode{2}{A !}]
        [\safranode{4}{AB}]
    ]
]
\end{forest}
\end{center}

Note, that, because we consider the order of children, those
two Safra trees are different:

\begin{center}
\begin{forest}safra,
[,phantom, s sep = 1cm
    [\safranode{0}{ABC}
        [\safranode{1}{A}]
        [\safranode{2}{B}]
    ]
    [\safranode{0}{ABC}
        [\safranode{2}{B}]
        [\safranode{1}{A}]
    ]
]
\end{forest}
\end{center}
This fact will be important for the construction, as the
order of the children will coincide with the order they are
added.

\begin{lemma}
    Given a non-deterministic Büchi automaton $\Bb$,
    there is an deterministic Muller automaton $\Mm$ that
    recognises the same languages as $\Bb$, that is, $\Ll(\Bb) = \Ll(\Mm)$.
\end{lemma}

\begin{proof}
    Let $\Bb = (Q, \Sigma, \delta, q_0, F)$ be a non-deterministic Büchi automaton.
    We build a deterministic automaton $\Mm = (Q', \Sigma, \delta', q'_0, \Ff')$
    with \begin{itemize}
        \item The states $Q'$ is the set of Safra trees on $Q$.
        \item The alphabet $\Sigma$ stays the same.
        \item The initial state is the Safra tree with
            only a root labeled with $\Bb$'s initial state $q_0$:
            \begin{center}
            \begin{forest}safra,
                [\safranode{0}{$q_0$}]
            \end{forest}
            \end{center}
        \item The transition function is deterministic
            and associates to each Safra tree $T$ and and input
            letter $s$ a new safra tree in 5 steps:
            \begin{enumerate}
                \item \emph{Branch off accepting states}: for each node labeled $l$ of $T$,
                    create a child node with label $F \cap l$ if it is not empty,
                    and take any name in $[1, \dots, 2\abs{Q}]$ that is not already taken.
                \item \emph{Power set}: replace each label $l \subseteq Q$ of $T$
                    by $\bigcup_{q \in l} \delta(q, s)$,
                    the set of state that are reachable from some state in $l$ while reading the letter $s$.
                \item \emph{Remove states}:
                    remove from each label (and its children) the states that appear also in older siblings.
                    Older siblings are nodes on the left of a given node, or equivalently
                    nodes with a smaller index in the sibling list.
                    At that point, labels of siblings are disjoints.
                \item \emph{Remove empty}:
                    remove all nodes that have an empty label, except the root.
                \item \emph{Mark nodes}: erase all $!$ marks, then mark each node with a $!$
                    if the union of its children labels
                    is the same as the parent label.
                    In that case, remove the whole tree below the marked node.
            \end{enumerate}
        \item The accepting condition is given
            by the family $\Ff' \subseteq \Pp(Q')$.
            A set $S \subseteq Q'$ of Safra trees belongs to $\Ff'$
            if some node name appears in each tree $s \in S$
            and in some tree $s \in S$, the node with this name carries a $!$ marker.
    \end{itemize}

    For detailed examples of this construction, see \autoref{sec:safra-examples}.
    We now prove that $\Ll(\Bb) = \Ll(\Mm)$ by double inclusion.

    Let $w \in \Ll(\Bb)$ be an infinite word.
    Since $w \in \Ll(\Bb)$, there is a run of the automaton $\Bb$
    that encounters infinitely many times an accepting state $q \in F$.
    We look at the corresponding run $r \in \infseq{Q'}$ in $\Mm$ and show that it
    is accepting. Each of $r_0$, $r_1$, \dots is a Safra tree.
    If the root node is marked infinitely many times with a
    $!$ in $r$, then $\Mm$ accepts $w$.
    Otherwise, at some point, $q$ is put on
    a son of the tree, and the Büchi run stays in a fixed
    son of the root.
    Indeed, every time the Büchi run encounters $q$,
    the root has a son with label $q$, as a result from
    either the \textit{Power set} or \textit{Branch off accepting states}
    rules. This node can be removed only by the \textit{Remove empty}
    or \textit{Remove states} rules, but since there is a Büchi run,
    the \textit{Power set} rule doesn't produce empty states after some point,
    and therefore the \textit{Remove empty} can only be applied as many times
    as the \textit{Remove states} rule. Finally, the \textit{Remove states}
    rule can be applied only finitely many times because it corresponds
    to push the Büchi run in an older sibling.
    We can then proceed recursively: either $k_1$ is marked infinitely
    many times and then $\Mm$ accepts, or it has a son $k_2$ in which the run ultimately stays.
    Since Safra trees have a depth of at most $|Q|$, there is a step
    at which a node is marked infinitely many times, and thus $\Mm$ accepts
    $w$.

    For the other inclusion, let $w \in \Ll(\Mm)$ be an infinite word
    and $r \in \infseq{Q'}$ the corresponding accepting run in $\Mm$.
    We need to construct a path
    $q \in \infseq{Q}$ in $\Bb$ that visits
    an accepting state infinitely many times.
    To that extent, the following claim will provide a
    way to find paths in $\Bb$ from paths in $\Mm$.

    \begin{claim}
        Let $n < m$ be integers and $N$ be the name of a node
        that occurs in all the Safra trees $r_n, r_{n+1}, \dots, r_m$.
        Let also $P \subseteq Q$ be the label of node $N$ in $t_n$
        and $R \subseteq Q$ the label of node $N$ in $t_m$.

        Then for all states $r \in R$ there exists
        a path from $p \in P$ to $r$ in the automaton $\Bb$
        that can be taken on input $w_n, \dots, w_{m-1}$.
        We write this as
        \[
            \Bb : P \pathto{w_{n..m}} R
            \quad\text{ for }\quad
            \forall r \in R~
            \exists p \in P
            \Par{
                \Bb : p \pathto{w_{m..m}} r
            }
        \]

        Furthermore, if the node $N$ is marked in both $r_n$
        and $r_m$, then any such path visits
        at least one accepting state of $\Bb$.
    \end{claim}
    \begin{proof}
        We this by induction on $m - n$. For the base case,
        if $m = n + 1$, each element of $R$ was produced by the \textit{Power set}
        rule, which means precisely that, $r \in R$ if and only if
        there is some $p \in P$ such that $r \in \delta(p, w_n)$.
        For the recursive case, let $P'$ be the label of node $N$ in
        $t_{m-1}$. By hypothesis, $\Bb : P \pathto{w_{n..m-1}} P'$
        and $\Bb : P' \pathto{w_{m-1..m}} R$. Since the relation is clearly
        transitive, it follows that $\Bb : P \pathto{w_{n..m}} R$.

        For the second part, let $S \subseteq Q$
        be the label of a son of node $N$. Since this son
        has been created by the \textit{Branch accepting} rule,
        it shows that every state $s \in S$ is reachable from $P$
        through an accepting state. If $R$ is marked, it means
        that the union of $N$ children is exactly $R$, and therefore
        every state in $R$ is reachable from $P$ via an accepting state.
    \end{proof}

    Since $\Mm$ accepts $w$,
    there is a node name $N$ that appears in every
    tree of $\Inf(r)$, and is marked with a $!$ in
    at least one tree of $\Inf(r)$.
    Let $P_0, P_1, \dots$ be the sequence of labels of $N$
    every time $N$ is marked. We have
    \[
        \set{q_0} \pathto{u_0} P_1 \pathto{u_1} P_2 \pathto{u_2} P_3 \pathto{} \dots
    \]
    where the $u_k$ are segments of $w$.
    Let $p_i \in Q^{\abs{u_i}}$ be the set of paths from $P_i$ to $P_{i+1}$
    that visit an accepting state on input $u_i$.
    Those are the path realise the fact that $\Bb : P_i \pathto{u_i} P_{i+1}$.
    Now, if we take two paths $v \in P_i$ and $v' \in P_{i+1}$,
    those might be stitched together to corresponds to
    a path on input $u_i \concat u_{i+1}$, if and only if
    $v_{\abs{u_i}} = v'_0$. In that case we write $v \sim v' :=
    v \concat v'_1 v'_2 \dots v'_{|v'|-1}$.

    Let $T$ be the set of paths that can that start at $q_0$
    and can be continued by paths from the $p_i$:
    \[
        T = \bigcup_{k=0}^{\infty} \setst{
                v_0 \sim v_1 \sim \dots \sim v_k
            }{
                \begin{array}{c}
                    \forall i \leq k~
                    v_i \in p_i \\
                    \wedge \\
                    v_0, \dots v_k
                    \text{ can be stitched}
                \end{array}
            }
    \]
    We can consider $T$ as a tree, by making it closed under prefix.
    In this case, each node of $T$ corresponds to a state in $\Bb$,
    This tree is infinite,
    since it has branches of unbounded length, and is finitely branching
    because the automaton $\Bb$ has finitely many states.
    By König's lemma there exists an infinite path $q$ in $T$.
    This path $q$ visits an accepting state infinitely many times
    on input $w$ because it is composed of paths from the sets $p_i$
    which each contains at least one visit to an accepting state.
    Therefore $q$ is an accepting run, and $w$ is accepted by $\Bb$.
\end{proof}

This concludes the proof of \autoref{thm:all-automata-are-the-same}:

\begin{theorem*}[\ref{thm:all-automata-are-the-same}]
    Let $L \subseteq \infseq\Sigma$ be a language.
    \[
        \begin{array}{c}
        L \text{ is recognised by a Büchi automaton} \\
        \iff \\
        L \text{ is recognised by a deterministic Muller automaton} \\
        \iff \\
        L \text{ is recognised by a deterministic parity automaton} \\
        \end{array}
    \]

    However, some languages are recognised by the above
    automata that cannot be recognised by any deterministic Büchi automaton.
\end{theorem*}

The following theorem is one of the main reasons for which we have
proven the above theorem. Indeed, we will later want to combine
automata to show that they have the same expressive power as
some formulas. To that extent, we need to be able to take
unions, intersections and complements of automata, which
correspond respectively to the disjunction, conjunction and negation of
formulas.

\begin{theorem}(Closure properties of Büchi automata)
    \label{thm:closure-of-buchi}
    The class of languages recognised by Büchi automata
    is closed under the operation of \begin{itemize}
        \item finite union;
        \item finite intersection;
        \item complementation.
    \end{itemize}
\end{theorem}
\begin{proof}
    Since we have proven that the three classes of Büchi,
    deterministic Muller and deterministic parity automata
    are equivalent, we can show the properties on any of the classes.

    We have already proven that parity automata are closed
    under union in \autoref{lem:muller-to-parity}
    and the closure under intersection
    is a direct consequence of the closure under union and complements.
    It suffices to show that Muller automata are closed under complements.

    This is clear however, as given a Muller automaton $\Mm = (Q, \delta, \Sigma, q_0, \Ff)$,
    the automata $\compl{\Mm} = (Q, \delta, \Sigma, q_0, \Pp(Q) \setminus \Ff)$
    accepts a run $r \in \infseq{Q}$ if and only if $\Inf(r) \in \Pp(Q) \setminus \Ff$, that is,
    $\Inf(r) \notin \Ff$, which corresponds to the fact that $\Mm$ does not accept $r$.
\end{proof}

\subsection{Example of the Safra construction}\label{sec:safra-examples}

In this section, we we look at a few instances of the Safra construction.
The following Büchi automaton on the language $\set{0, 1}$ recognises
all the infinite words that have infinitely many \verb|1|
but only finitely many \verb|11|.

\begin{center}
    \input{fig/buchi-1-no-11.tex}
\end{center}

Converting this automaton to a deterministic Müller automaton,
we obtain the following:

\begin{center}
    \scalebox{0.88}{\input{fig/muller-1-no-11.tex}}
\end{center}

Which accepts a run if the set of states that occur infinitely many times
is any subset of
\[
\set{
\pbox[c]{2cm}{\begin{forest}safra,
    [\safranode{0}{AB} [\safranode{1}{B}]]
\end{forest}}
~~
\pbox[c]{2cm}{\begin{forest}safra,
    [\safranode{0}{AB} [\safranode{1}{B !}]]
\end{forest}}
~~
\pbox[c]{2cm}{\begin{forest}safra,
    [\safranode{0}{ABC} [\safranode{1}{C}]]
\end{forest}}
}
\]

However, only two of those subsets are relevant here,
because they are the only ones corresponding to loops containing
a node with \verb|!| in the graph of the Müller automaton.
Those two sets are
\[
\set{
\pbox[c]{2cm}{\begin{forest}safra,
    [\safranode{0}{AB} [\safranode{1}{B}]]
\end{forest}}
~~
\pbox[c]{2cm}{\begin{forest}safra,
    [\safranode{0}{AB} [\safranode{1}{B !}]]
\end{forest}}
~~
\pbox[c]{2cm}{\begin{forest}safra,
    [\safranode{0}{ABC} [\safranode{1}{C}]]
\end{forest}}
}
\andquad
\set{
\pbox[c]{2cm}{\begin{forest}safra,
    [\safranode{0}{AB} [\safranode{1}{B !}]]
\end{forest}}
~~
\pbox[c]{2cm}{\begin{forest}safra,
    [\safranode{0}{ABC} [\safranode{1}{C}]]
\end{forest}}
}
\]

We now look at how to compute the transitions table of the Müller automaton.
The initial state is \inlinesafra{\safranode{0}{A}} since the initial state
of the Büchi automaton is A.
Then, whether a \verb|0| or a \verb|1| is read,
it is possible to transition to states A and B.
All rules except the \textit{Power set} rule do nothing here:

\begin{center}
    \begin{forest}safra,
        [{\nodepart{one}0\nodepart{two}A}]
    \end{forest}
    $\xto{\substack{\text{Branch}\\\text{accepting}}}$
    \begin{forest}safra,
        [{\nodepart{one}0\nodepart{two}A}]
    \end{forest}
    $\xto{\substack{\text{Power}\\\text{set}}}$
    \begin{forest}safra,
        [{\nodepart{one}0\nodepart{two}AB}]
    \end{forest}
    $\xto{\substack{\text{Make}\\\text{disjoint}}}$
    \begin{forest}safra,
        [{\nodepart{one}0\nodepart{two}AB}]
    \end{forest}
    $\xto{\substack{\text{Remove}\\\text{empty}}}$
    \begin{forest}safra,
        [{\nodepart{one}0\nodepart{two}AB}]
    \end{forest}
    $\xto{\substack{\text{Mark}\\\text{nodes}}}$
    \begin{forest}safra,
        [{\nodepart{one}0\nodepart{two}AB}]
    \end{forest}
\end{center}

We now need to compute the transitions from \inlinesafra{\safranode{0}{AB}}.
When the autmaton reads \verb|0| in the state A or B,
we can reach the state A (from A) or B (from both A and B).
The other rules don't apply here, so the transition is
$\inlinesafra{\safranode{0}{AB}} \xto{~0~} \inlinesafra{\safranode{0}{AB}}$.
However, if \verb|1| is read, the set of reachable states
is $\set{A, B, C}$. The transition is thus
$\inlinesafra{\safranode{0}{AB}} \xto{~1~} \inlinesafra{\safranode{0}{ABC}}$.

The transition from \inlinesafra{\safranode{0}{ABC}} on input \verb|0|
makes also use of the \textit{Branch accepting} rule,
since C is an accepting state. According to this rule,
we add a new node with a name that is not yet present in the
tree, here 1, and create a son with label the set of
accepting states of the node 0, which is just $\set{C}$.
We then apply the \textit{Power set} rule to each node.
The new node that we have added, \inlinesafra{\safranode{1}{B}},
tells us that if we are in B, then we have seen an accepting node (here C) before.

\begin{center}
\begin{forest}safra,
    [{\nodepart{one}0\nodepart{two}ABC}]
\end{forest}
$\xto{\substack{\text{Branch}\\\text{accepting}}}$
\begin{forest}safra,
    [{\nodepart{one}0\nodepart{two}ABC}
        [{\nodepart{one}1\nodepart{two}C}]]
\end{forest}
$\xto{\substack{\text{Power}\\\text{set}}}$
\begin{forest}safra,
    [{\nodepart{one}0\nodepart{two}AB}
        [{\nodepart{one}1\nodepart{two}B}]]
\end{forest}
\end{center}

If we continue from this Safra tree and read \verb|0| or \verb|1|
we obtain the two following transitions by using only the \textit{Power set}:
\[
    \inlinesafra{\safranode{0}{AB} [\safranode{1}{B}]}
    \xto{~0~} \inlinesafra{\safranode{0}{AB} [\safranode{1}{B}]}
    \andquad
    \inlinesafra{\safranode{0}{AB} [\safranode{1}{B}]}
    \xto{~1~} \inlinesafra{\safranode{0}{ABC} [\safranode{1}{C}]}
\]


Finally we look at what happens if we read \verb|1| from \inlinesafra{\safranode{0}{ABC} [\safranode{1}{C}]},
because every rule is used. Since both node 0 and 1 contain C, we need to create a new node below them
that contain C. Since the Büchi automaton has three nodes,
we pick non-used labels in $\set{0, 1, \dots, 6}$ and create two a new child
for each. We then apply the \textit{Power set}
rule to each of the four nodes.

\begin{center}
\begin{forest}safra,
    [{\nodepart{one}0\nodepart{two}ABC}
      [{\nodepart{one}1\nodepart{two}C}]]
    \end{forest}
    $\xto{\substack{\text{Branch}\\\text{accepting}}}$
    \begin{forest}safra,
    [{\nodepart{one}0\nodepart{two}ABC}
      [{\nodepart{one}1\nodepart{two}C}
        [{\nodepart{one}3\nodepart{two}C}]]
      [{\nodepart{one}2\nodepart{two}C}]]
    \end{forest}
    $\xto{\substack{\text{Power}\\\text{set}}}$
    \begin{forest}safra,
    [{\nodepart{one}0\nodepart{two}AB}
      [{\nodepart{one}1\nodepart{two}B}
        [{\nodepart{one}3\nodepart{two}B}]]
      [{\nodepart{one}2\nodepart{two}B}]]
    \end{forest}
\end{center}

Now, both nodes 1 and 2 contain B, so we remove B from
the newest node, which is 2 in this case. The idea behind
this is that we do not need to keep track multiple times of what
happens after we see state B, and all the information about runs That
visit B will already be contained in node 1 or its children.
We then remove node 2 entirely with the \textit{Remove empty} rule.
Finally, the \textit{Mark nodes} rule is used on node 1, since
its only child has the same label. We therefore remove node 3 and add a
$!$ marker to node 1.

\begin{center}
    \begin{forest}safra,
    [{\nodepart{one}0\nodepart{two}AB}
      [{\nodepart{one}1\nodepart{two}B}
        [{\nodepart{one}3\nodepart{two}B}]]
      [{\nodepart{one}2\nodepart{two}B}]]
    \end{forest}
    $\xto{\substack{\text{Make}\\\text{disjoint}}}$
    \begin{forest}safra,
    [{\nodepart{one}0\nodepart{two}AB}
      [{\nodepart{one}1\nodepart{two}B}
        [{\nodepart{one}3\nodepart{two}B}]]
      [{\nodepart{one}2\nodepart{two}$\emptyset$}]]
    \end{forest}
    $\xto{\substack{\text{Remove}\\\text{empty}}}$
    \begin{forest}safra,
    [{\nodepart{one}0\nodepart{two}AB}
      [{\nodepart{one}1\nodepart{two}B}
        [{\nodepart{one}3\nodepart{two}B}]]]
    \end{forest}
    $\xto{\substack{\text{Mark}\\\text{nodes}}}$
    \begin{forest}safra,
    [{\nodepart{one}0\nodepart{two}AB}
      [{\nodepart{one}1\nodepart{two}B !}]]
    \end{forest}
\end{center}

If we look at all the paths the Büchi automaton might have taken
since the creation of this node, the $!$ mark indicates
that there is a way to reach any state on the label of the node
and visit an accepting state along the way.
It doesn't mean that all paths since the creation of the node
did visit an accepting state, but there's some path that did.
This is also true if we consider the possible paths since
the node was previously marked,
as all children have been removed
when marking the node, and have since been re-created by visiting an
accepting state (via the \textit{Branch accepting} rule).

\paragraph*{}
Notice that this construction can produce very complex
automata, even if there exists a simpler Muller automaton
for the same language. For instance,
the following Büchi automaton consisting of only four states

\begin{center}
    \begin{tikzpicture}[>=latex',join=bevel,node distance=3cm]
    \node[state, initial] (0) {};
    \node[state, right of=0] (3) {};
    \node[state, accepting, right of=3] (1) {};
    \node[state, ] at (60:3cm)  (2) {};

    \path (0) edge[edge1, bend left] node {1} (3)
          (2) edge[edge0, loop above] (2)
              edge[edge1] node {1} (0)
          (3) edge[edge0, bend left] node {0} (0)
              edge[edge1] node {1} (2)
              edge[edge1, bend left] node {1} (1)
          (1) edge[edge0, bend left] node {0} (3);
    \end{tikzpicture}
\end{center}
produces a Muller automaton with 105 states depicted on the next page.
This is not because this automaton recognises a very complex language
but rather that that each nod of Safra trees has a label and
by following path of different length there can be multiple tree that have
the same labels but different names.

For instance the tree below has six nodes labeled with the with $\set{0, 1, 2, 3}$,
$\set{1, 2, 3}$ and $\set{3}$, but only the labels changes.

\begin{center}
\begin{forest}safra,
[,phantom, s sep = 1cm
    [\safranode{0}{0123}
        [\safranode{1}{123}
            [\safranode{4}{3}]
        ]
    ]
    [\safranode{0}{0123}
        [\safranode{2}{123}
            [\safranode{3}{3}]
        ]
    ]
    [\safranode{0}{0123}
        [\safranode{3}{123}
            [\safranode{4}{3}]
        ]
    ]
    [\safranode{0}{0123}
        [\safranode{1}{123}
            [\safranode{3}{3}]
        ]
    ]
    [\safranode{0}{0123}
        [\safranode{3}{123}
            [\safranode{2}{3}]
        ]
    ]
    [\safranode{0}{0123}
        [\safranode{2}{123}
            [\safranode{4}{3}]
        ]
    ]
]
\end{forest}
\end{center}

There is however, no obvious way to remove the names of each node
as they are required in some cases to have the correct output.

\includepdf{fig/large-safra.pdf}

% \begin{center}
% \begin{tikzpicture}[node distance=2.5cm]
%     \node[state, initial] (A) {A};
%     \node[right of=A] (ghost) {};
%     \node[state, right of=A] (B) {B};
%     \node[state, below of=A] (D) {D};
%     \node[state, accepting, right of=B] (C) {C};
%     \node[state, right of=D] (E) {E};
%     \node[state, below of=D] (F) {F};
%     \node[state, accepting, below of=E] (G) {G};
%     \path[->] (A) edge[loop above, edge0] (A)
%                 edge[loop below, edge1] (A)
%                 edge[bend left, edge0] (B)
%                 edge[bend right, edge1] (B)
%                 edge[bend left, edge0] (D)
%                 edge[bend right, edge1] (D)
%               ;
% \end{tikzpicture}
% \end{center}



\section{Monadic second order logic}
\subsection{Definition}

The goal of this section is to introduce the reader
to some extensions of first order logic (FO),
and most importantly to develop monadic second order logic.

In first order logic, quantifications happen only over the
domain elements.
Second order logic (SO) is a generalization of FO,
where quantification over relations is allowed.
It adds second order variables, usually denoted by capital
letters, that are interpreted by relations, that is,
if the relation is of arity $n$, subsets of $\Mm^n$.

For instance, the following formulas are syntactically valid:
\begin{itemize}
    % \item $\forall P~ \exists x~ \forall y~ P(x) \implies P(y)$,
    %     where $P$ is a variable of arity $1$.
    \item If the language contains the symbol $\leq$
        and $A$ is a second order variable of arity 1, then:
    \[
        \forall A ~ \exists x ~
            (A(x) \implies \forall y ~
                (A(y) \implies x \leq y)
    \]
        is a formula expressing that every subset of the model
        a has a minimal element.
    \item If the language contains a binary relation $E$
        and $M$ is a second order variable of arity 2,
        consider
        \[
            \exists M\, \forall x\, \forall y \,
            \bigparenthesis{M(x, y) \implies E(x, y)}
            \wedge \forall x \, \exists! y \, M(x, y).
        \]
        If $E$ is symmetrical, we can view any model as an
        undirected graph with edges given by $E$, then
        the formula above expresses the fact that
        there exists a perfect matching, namely $M$.
\end{itemize}

\begin{definition}
    Given a vocabulary $\sigma$ consisting of relations
    and constants symbols,
    the \emph{terms} of SO are constants symbols and first order variables.

    The \emph{atomic formulas} are of the form:
    \begin{itemize}
        \item $t = t'$ when $t, t'$ are terms.
        \item $R(t_1, \dots, t_n)$ when $t_1, \dots, t_n$ are terms
            and $R \in \sigma$ is a relation of arity $n$.
        \item $X(t_1, \dots, t_n)$ when $t_1, \dots, t_n$ are terms
            and $X$ is a second-order variable of arity $n$.
    \end{itemize}

    The set of SO \emph{formulas} is the smallest set that contains
    all atomic formulas and is closed under:
    \begin{itemize}
        \item boolean operators: $\neg$, $\wedge$, $\vee$ and first order quantification
        \item second order quantification: if $\phi(\vec{x}, Y, \vec{X})$
            is a SO formula, then $\forall Y \phi(\vec{x}, Y, \vec{X})$
            and $\exists Y \phi(\vec{x}, Y, \vec{X})$ are SO formulas.
    \end{itemize}

    The \emph{semantic} of SO logic is defined similarly to FO logic
    so we only need to define the semantics for new constructs.
    Let $\Mm$ be a $\s$-structure and $\phi(x_1, \dots, x_k, X_1, \dots, X_n)$
    a SO formula. We define $\Mm \models \phi(\vec{b}, \vec{B})$
    where $b \in \Mm^k$ is a tuple of elements of $\Mm$
    and if $X_i$ is of arity $n_i$, then $B_i$ is a subset of $\Mm^{n_i}$.

    \begin{itemize}
        \item If $\phi(x_1, \dots, x_k, X)$ is $X(t_1, \dots, t_n)$
            with $X$ a second-order variable of arity $n$
            and $t_1, \dots, t_n$ terms with free variables
            among $x_1, \dots, x_i$, then
            $\Mm \models \phi(\vec{b}, B)$
            if $(t_1^\Mm\vec{b}), \dots, t_k^\Mm(\vec{b}))$ is in $B$.
        \item If $\phi(\vec{x}, Y, \vec{X})$ is $\forall Y \psi(\vec{x}, Y, \vec{X})$
            with $Y$ a second-order variable of arity $n$
            then $\Mm \models \phi(\vec{b}, B)$
            if for all $C \subseteq \Mm^n$, $\Mm \models \psi(\vec{x}, C, \vec{X})$
        \item If $\phi(\vec{x}, Y, \vec{X})$ is $\exists Y \psi(\vec{x}, Y, \vec{X})$
            with $Y$ a second-order variable of arity $n$
            then $\Mm \models \phi(\vec{b}, B)$
            if for some $C \subseteq \Mm^n$, $\Mm \models \psi(\vec{x}, C, \vec{X})$
    \end{itemize}
\end{definition}

We will not study much of second order logic, but instead
look at one of its fragments, monadic second order logic.

\begin{definition}
\emph{Monadic second order logic} or MSO is an extension of
fisrt order logic and a restriction of second order logic.
In MSO, valid formulas are formulas of second order logic
where second order quantification happens only on unary relations.
This corresponds to being able to quantify over elements
of the domain (first-order quantification)
or over subsets of the domain (second-order quantification).

The semantics of MSO is the same as SO semantics.
\end{definition}

\begin{examples}
    We give some formulas of MSO in the context of directed graphs,
    that is, we consider models of MSO with only one
    symbol of relation, $E$ of arity 2. We read $E(x, y)$
    as there is an edge between $x$ and $y$.

    The following formula states that a graph is disconected:
    \[
        \underbrace{
            \exists X
        }_{\text{there exists a set}}
        \underbrace{
            \Par{
                \forall x~
                \forall y~
                X(x) \wedge E(x, y)
                \implies X(y)
            }
        }_{\text{closed under neighbours}}
        \wedge
        \underbrace{
            \Par{
                \exists x~ X(x)
            }
            \wedge
            \Par{
                \exists x~ \neg X(x)
            }
        }_{\text{and neither empty or full}}
    \]
    And this formula states that it is 3-colorable:
    \begin{align*}
        \underbrace{
            \exists X_1\, \exists X_2\, \exists X_3
        }_{\text{there exists three sets}}
        & \underbrace{
                \forall x~
                X_1(x) \vee X_2(x) \vee X_3(x)
        }_{\text{covering the graph}}
        \\& \wedge \underbrace{
            \forall x~
            \bigwedge_{i \neq j} \Par[1]{
                X_i(x) \implies \neg X_j(x)
            }
        }_{\text{disjoint}}
        \\& \wedge \underbrace{
            \forall x~
            \forall y~
            E(x, y) \implies
            \bigwedge_{i = 1..3} \Par[1]{
                X_i(x) \implies \neg X_i(y)
            }
        }_{\text{and no edge has twice the same color}}
    \end{align*}
    Note that here the symbols $\bigwedge$ are not part of the language of MSO,
    they are meta shorthands to indicate the longer formula it expands to.
\end{examples}

The examples above show that MSO has more expressive power than first
order logic, as those formulas cannot be expressed in FOL.
However, checking whether some MSO formula hold on a given graph
is computationally hard, as this problem belongs to $\PSPACE$.
It even belongs to $\PSPACE$ when the graph (but not the formula)
is fixed, as \textsc{QBF} can be encoded straightforwardly in MSO
on the graph with only one vertex.

\subsection{Decidability}


The decidability problem for monadic second order logic,
in general, is impossible, because it contains first order logic.
However, in monadic second order logic, the theory of \N with
the successor (S1S) has been shown to be decidable.
This theory is also called the theory of infinite strings
for reasons that will be clear in the next section.

\begin{definition}
    Let $n \in \N$ be a positive integer.
    A \emph{language}  of S1S is $\Ll = \set{\Symbol{0}, \Symbol{S}, \Symbol{<}, \Symbol{P_1}, ..., \Symbol{P_n}}$,
    where $0$ is a constant symbol, $S$ is a unary function,
    $<$ is a binary relation, and the $P_i$ are unary relations.

    Let $P_1, \dots, P_n \subseteq \N$. A model of S1S is
    $\Mm = \set{\N, 0, +1, <, P_1, ..., P_n}$,
    where the domain is always \N, $S^\Mm = +1$ is the successor function
    which maps $x$ to $x+1$, $<^\Mm$ is interpreted as the usual order
    on \N, and $P_i^\Mm = P_i$.

\end{definition}

\begin{remark}
To get a model of S1S, we only need to give the sets $P_1, \dots, P_n$.
Therefore, a model can be coded by an \w-word $\Pp \in \infseq{(\IB^n)}$
where $i \in P_k \iff (\Pp_i)_k = 1$.

In other words, each letter of the \w-word $\Pp$ is a $n$-tuple of
$0$'s and $1$'s, and if the $k$-th element of $i$-th letter is a 1,
then $P_i(k)$ holds.
\end{remark}

The reason why S1S is called the theory of infinite strings
is because its models can be considered as words on the
alphabet $\Pp(\set{P_1, \dots, P_n})$.

An other reason is that
if for each $i \in \N$, there is exactly
one of the $P_1(i), \dots, P_n(i)$ that hold, then
we can represent the model as an infinite string
on the alphabet $\Sigma = \set{P_1, \dots, P_n}$.

Those two reasons will be used to change our setting from
models of S1S to and from \w-languages recognised by automata.

\paragraph{}
The semantics of S1S are the same as MSO. However,
we only use \N as the universe for first order variables
and $2^\N$ as the universe for second order variables.
If $w \in \infiniteWords$ is an infinite word inducing
the model $\Mm = \set{\N, 0, +1, <, P_1, ..., P_n}$,
and $\phi(X_1, \dots, X_n)$
is a S1S formula with $n$ free second order variables,
we write \[
    w \models \phi(X_1, \dots, X_n)
    ~~\iff~~
    \Mm \models \phi_{[P_1/X_1, \dots, P_n/X_n]}
\]

\begin{definition}
    An \w-language $L \subseteq \infseq{(\IB^n)}$ is
    \emph{S1S-definable} if there is some S1S formula
    $\phi(X_1, \dots, X_n)$ such that
\[
    L = \setst{w \in \infseq{(\IB^n)}}{
        w \models \phi(X_1, \dots, X_n)
    }
\]
\end{definition}

\begin{example}
    $L = \setst{w \in \infseq{\IB}}{w \text{ has infinitly many 1's}}$
    is first order definable by
    $\phi(X_1) = \forall s\, \exists t\, (s < t \wedge X_1(t))$
\end{example}



\begin{lemma}\label{lemma:buchi-definable}
    A Büchi-definable \w-language is S1S-definable.
\end{lemma}

\begin{proof}
    Let $\Aa = (Q, \Sigma, \delta, q_1, F)$ be a Büchi automaton.
    We need to construct a formula $\phi(X_1, \dots, X_n)$
    such that for all \w-word $w \in \infseq{\Sigma}$
    we have $w \models \phi(X_1, \dots, X_n)$
    if and only if $\Aa$ accepts $w$.
    For this, we set $n := \abs{\Sigma}$ and \[
        \phi(X_1, \dots, X_n) =
            \exists Q_1, \dots, Q_{n} ~
            \phi_{part}
            \wedge
            \phi_{start}
            \wedge
            \phi_{trans}
            \wedge
            \phi_{accept}
    \]
    Informally, for each integer $t$ there is exactly one
    of the $Q_i$ such that $t \in Q_i$, which corresponds
    to the state of the automaton on an accepting run.
    Formally,
    \begin{itemize}
        \item $\phi_{part}$ asserts that the sets $Q_1, \dots, Q_{n}$
            form a partition of $\N$
            \[\phi_{part}(Q_1, \dots, Q_n) :=
                \forall t \bigvee_{i=1..n} Q_i(t)
                \wedge
                \forall t \bigwedge_{i \neq j}
                    \neg \parenthesis{Q_i(t) \wedge Q_j(t)}
            \]
        \item $\phi_{start}$ encodes the facts that a run
            must start at $q_1$, so \[
                \phi_{start}(Q_1, \dots, Q_n) := Q_1(0)
            \]
        \item $\phi_{trans}$ encodes the transition function.
            \[
                \phi_{trans}(Q_1, \dots, Q_n) =
                \forall t~
                \bigwedge_{q' \notin \delta(q, l)}
                    Q_q(t) \wedge X_l(t) \implies \neg Q_{q'}(t + 1)
            \]
            where the conjunction is on every triple $(q, l, q') \in
                Q \times \Sigma \times Q$ such that $q' \notin \delta(q, l)$.
            This corresponds to forbidding the automaton to
            move from the state $q$ to $q'$ by reading the letter $l$.
            Note that we do not need to explicitly require that the
            automaton goes to some state in $\delta(q, l)$ as
            the fact that the $Q_i$ form a partition already requires
            that the automaton goes to \textit{some} state.
        \item $\phi_{accept}$ encodes the fact that the automaton
            visits infinitely many times an accepting state:
            \[
                \phi_{accept}(Q_1, \dots, Q_n) =
                \forall t\, \exists s\, \Bigparenthesis{
                    t < s \wedge \bigwedge_{i \in F} Q_i(t)
                }
            \]
    \end{itemize}

    By construction, if there is an accepting run $r \in \infseq{Q}$
    then we have $w \models \phi(X_1, \dots, X_n)$ (where, remember, the $X_i$
    are interpreted as the set of integer where $w$ has the letter $i$).
    On the other side, if $w \models \phi$, an accepting run
    is given by the sets $Q_1, \dots, Q_{n}$ by $r_i = j$
    if and only if $i \in Q_j$. This is well defined because the $Q_i$
    form a partition of $\N$, and corresponds to an accepting run
    since it starts at $q_1$ (by $\phi_{start}$),
    moves according to the transition function (by $\phi_{trans}$)
    and visits infinitely many time an accepting state(by $\phi_{accept}$).
\end{proof}

We will later show that the converse is also true,
that is, given some S1S-decidable language,
we can build a Büchi automaton that recognises the same
language. The two notions are therefore equivalent.

To that extent, we will introduce deterministic Muller
automata and show that they are equivalent to (non-deterministic)
Büchi automata. This will be used to show
that it is possible to complement a Büchi automaton.
We will then show that S1S is equivalent
to a simpler version with fewer constructs, $\text{S1S}_0$.
Finally, we will show that Büchi automata are as expressive
as $\text{S1S}_0$ formulas.


\begin{definition}
    A formula is a $\text{S1S}_0$ formula if
    \begin{itemize}
        \item its atomic formulas are one of $X \subseteq Y$,
            $\Succ(X, Y)$ or $\Sing(X)$, for $X$ and $Y$ some second
            order variable. We interpret that $X \subseteq Y$ holds
            if $X$ is a subset of $Y$, $\Succ(X, Y)$ holds if
            $(X, Y) = (\set{a}, \set{a+1})$ for some $a \in \N$ and
            $\Sing(X)$ holds if $X = \set{a}$ for some $a$.
        \item The only connectors are $\vee$ and $\neg$
        \item The only quantifiers are second order existential quantifers.
    \end{itemize}
\end{definition}

\begin{lemma}
    \label{lemma:s1s-is-s1s-0}
    Every S1S formula $\phi(X_1, \dots, X_n)$ has
    an equivalent $\text{S1S}_0$ formula $\phi_0(X_1, \dots, X_n)$.
\end{lemma}

\begin{proof}
    First, we know that we can eliminate all conjunction with De Morgan's
    laws and replace all implications with their definition. Similarly, we can eliminate universal quantifiers
    since $\forall x\, \psi(x) \iff \neg \exists x\, \neg \psi(x)$.

    We can eliminate the constant $0$, by using a fresh variable (say $z$)
    that does not appear in $\phi$. Then, $\phi$ is equivalent to
    \[
        \exists z~ \bigparenthesis{\neg\exists x\, (x < z) \wedge \phi_{[z:=0]}}
    \]
    where $\phi_{[z := 0]}$ is the formula where every 0 of $\phi$ is replaced by $z$.

    The formula $x < y$ is equivalent to \[
        \forall X~ \Bigparenthesis{
            X(x) \wedge \forall t \bigparenthesis{X(t) \implies X(S(t))}
        } \implies X(y)
    \]
    That is, every set that contains $x$ and is closed under the successor
    function also contains $y$.

    Then we can ensure that the successor function occurs only
    in formulas of the form $S(x) = y$. For instance,
    we replaces instances of $X(S(S(x)))$ by \[
        \exists s \exists t \bigparenthesis{
            S(x) = s \wedge S(s) = t \wedge X(t)
        }
    \]
    We can similarly remove all instances of the form $S(...(S(x)...) = S(...(S(y)...)$
    by adding intermediate variables.

    We have shown so far that we can consider formulas
    that consist only of $S(x) = y$, $X(x)$, connectors $\neg$ and $\wedge$
    and first and second order existential quantifiers.
    In order to remove completely first order variables and quantifers,
    we need to modify every occurence of first order variables:
    \begin{itemize}
        \item If $\phi$ is of the form $\exists x~ \psi(x)$, we replace it by
            $\exists X ~ \Sing(X) \wedge \psi_{[X/x]}$ where $X$ is a variable not apearing
            in $\psi$.
        \item If $\phi$ is $X(y)$, we replace it by $\Sing(Y) \wedge Y \subseteq X$
        \item If $\phi$ is $x' = y$ we replace it by $\Succ(x, y)$.
    \end{itemize}
\end{proof}

\begin{theorem}
    \label{thm:buchi-iff-s1s}
    An \w-language is Büchi-definable if and only if
    it is S1S definable.
\end{theorem}

\begin{proof}
    Let $L$ be an \w-language. By \autoref{lemma:buchi-definable},
    we know that if it is Büchi-definable, it is S1S-definable.

    For the other direction,
    % will show only for the case
    % where the alphabet is $\IB = \set{0, 1}$ as the proof
    % in the general case adds only more verbose formalism and no new ideas.
    by \autoref{lemma:s1s-is-s1s-0}, formulas of S1S
    are as expressive as formulas of $\text{S1S}_0$,
    so it suffices construct a Büchi automaton
    that corresponds to each $\text{S1S}_0$ formula.
    We consider formulas of the form
    $\phi(P_1, \dots, P_n, X_1, \dots, X_m)$
    where \begin{itemize}
        \item the $P_i$ are the second order variables that
            correspond to the \w-word.
        \item the $X_i$ are second order free variables.
    \end{itemize}
    We will abbreviate this as $\phi(\vec P, \vec X)$,
    as it does not matter for the construction
    which of the second order variable is which.
    It is only relevant to keep in mind that some
    of those variables correspond to the unary relations
    of the model.

    For each such formula, we construct an
    automaton on the language $\IB^n \times \IB^m = \IB^{n+m}$
    such that given any $\vec P$ and $\vec X$, $\phi$ holds
    if and only if the automaton accepts the word $(\vec P, \vec X)$.

    We proceed by induction on the height of the formula $\phi$.
    \begin{itemize}
        \item If $\phi(X, Y)$ is $X \subseteq Y$,
            a corresponding automaton is:
            \begin{center}
            \begin{tikzpicture}[automata]
                \node[initial, state, accepting] (A) {};
                \draw (A) edge[loop above]
                    node {$\begin{array}{c}
                        (0, 0) \\
                        (0, 1) \\
                        (1, 1)
                    \end{array}$} (A);
            \end{tikzpicture}
            \end{center}
            In this automaton, an infinite run is possible
            if and only if each digit of $X$ is smaller that the
            corresponding digit of $Y$, so the only impossible case is $(1, 0)$,
            which would correspond to having some $x \in X$ that does not belong to $Y$.

        \item If $\phi(X, Y)$ is $\Succ(X, Y)$,
            a corresponding automaton is:
            \spacedAutomata{
                \node[state, initial] (q0) {};
                \node[state, right of=q0] (q1) {};
                \node[state, accepting] (q2) [right of=q1] {};

                \draw (q0) edge [loop above] node {$(0, 0)$} (qo)
                    edge node {$(1, 0)$} (q1)
                    (q1) edge node {$(0, 1)$} (q2)
                    (q2) edge [loop above] node {$(0, 0)$} (q2);
            }
            There, a one must be read in $X$ just before it is read in $Y$,
            and nowhere else.

        \item If $\phi(X)$ is $\Sing(X)$,
            a corresponding automaton is
            \spacedAutomata{
                \node[state, initial] (q0) {};
                \node[state, accepting, right of=q0] (q1) {};
                \draw (q0)
                    edge node {$1$} (q1)
                    edge [loop above] node {$0$} (q0)
                    (q1)
                    edge [loop above] node {$0$} (q1)
                    ;

            }

        \item If $\phi(\vec X)$ is $\psi(\vec X) \vee \chi(\vec X)$,
            or $\neg \psi(\vec X)$
            where $\psi$ and $\chi$ have equivalent automaton,
            we know by \autoref{thm:closure-of-buchi}
            that the class of Büchi automata
            is closed under union and complementation,
            so there is a automaton corresponding to $\phi$.

        \item If $\phi(\vec X)$ is $\exists Y~ \psi(\vec X, Y)$
            and $A$ is the automaton corresponding to $\psi(\vec X, Y)$,
            an automaton for $\phi$ is a copy of $A$
            in which the transition constraint for the variable $Y$
            are erased. That is, if $A$ works on the alphabet $\IB^{k+1}$
            and has a transition function $\delta: \IB^{k+1} \times S \to \Pp(S)$,
            then the automaton $A'$ for $\phi$ works on the alphabet $\IB^{k}$
            and has transition function \[
                \func{\delta'}{\IB^k \times S}{\Pp(S)}
                    {(b, s)}{
                        \bigcup_{y \in \IB} \delta\bigparenthesis{(b_1, \dots, b_k, y), s}
                    }
            \]
            It is the projection on the coordinate $Y$ of the automaton $A$.
    \end{itemize}

\end{proof}

Given a S1S formula, we want to know whether it admits a model, that is,
if some infinite word satifies the formula. The following theorem
tells us that this problem is decidable.

\begin{theorem}
    The satisfiability problem for S1S is decidable.
\end{theorem}
\begin{proof}
    Let $phi$ be a S1S formula. By \autoref{thm:buchi-iff-s1s} we have
    an automaton \Aa that recognise the same words as \phi accepts.
    It suffices to know whether \Aa recognises at least one word.

    It is easy to find wether a Büchi automaton accepts at least one word,
    and if so, to give one such word. Indeed, it suffices to find
    a cycle in the graph of the automaton which is reachable from
    the initial state and which contains an accepting state.
    this can be done by a depth first search.
\end{proof}

\subsection{Bisimilarity}

In this section, we will look at another remarkable fact
about MSO, which brings it closer to theoretical computer science.
An important class of objects in theoretical computer science
is the class of labelled transition systems,
which are directed graphs with labels on both the edges and vertices.
Those labels correspond to different kinds of transitions
that can happen from one state to the other. It is a concept similar
to automata but without a notion of initial and accepting states.
It also differs from automata as the set of states and transitions are not necessarily finite
and not even countable.

\begin{definition}
    Given to sets of symbols $P$ and $M$,
    a \emph{labeled transition system}
    is a quadruple $\IS = (S, \Lambda, \Gamma, R, V)$, where:
    \begin{itemize}
        \item $S$ is a set of \emph{states}.
        \item $\Lambda$ is a set of \emph{edge labels}.
        \item $\Gamma$ is a set of \emph{state labels}.
        \item $R: \Lambda \to \Pp(S \times S)$ is the transition rule,
            so that for $\alpha \in \Lambda$, $R(\alpha)$ is a binary relation
            that discribes a directed graph on $S$.
        \item $V: \Gamma \to \Pp(S)$ describes the state labels,
            so that for $\alpha \in \Gamma$,
            $V(\alpha)$ is the set of state labelled with $\alpha$.
    \end{itemize}

    Note that this notion encompasses that of Kripke's structure.
\end{definition}

We will look at the notion of bisimilarity, or bisimulation, which is
an equivalence relation on labelled transition systems.
Intuitively, two labelled transition systems are bisimilar if
they can simulate each other and an observer cannot distinguish
between them.
We formalise the idea of being undistinguishable
by an observer with Ehrenfreucht-Fraïssé games.

\begin{definition}
    Let $\IS = (S, \Lambda, \Gamma, R, V)$
    and $\IT = (T, \Lambda, \Gamma, R', V')$
    be two labeled transition system that share the same set of labels.

    The \emph{Ehrenfreucht-Fraïssé game} of \IS and \IT is
    an infinite game, between two players that we
    call \Attacker and \Defender.
    The game plays as follows:
    \begin{enumerate}
        \item The \Attacker picks a model $M \in \set{\IS, \IT}$,
            and a state $q_A \in M$
        \item Let $M' \in \set{\IS, \IT}$ be the model not chosen by the \Attacker.
            The \Defender picks a state $q_D \in M'$
            such that $q_A$ and $q_D$ have the same labels.
            That is, for every state label $\alpha \in \Gamma$,
            $q_A \in V(\alpha)$ if and only if $q_D \in V(\alpha)$.

        \item At each turn, let $(p, p') \in M \times M'$ be the two states $q_A$ and $q_D$ picked by the two players
            in the last turn.
            the \Attacker picks $p_A \in \set{p, p'}$
            and a transition $p_A \xto{\alpha} q_A$
            for some $\alpha \in \Lambda$ and $q_A$ in the same model as $p_A$.
        \item To a move $p_A \xto{\alpha} q_A$
            the \Defender picks a transition $p_D \xto{\alpha} q_D$.
            where $p_D$ is the state of $\set{p, p'}$ not picked by the \Attacker,
            and $q_D$ is in the same model as $p_D$
            and such that $q_A$ and $q_A$ have the same labels.
        \item If a player cannot pick a transition,
            he loses the game. Otherwise, if the game is infinitely long,
            the \Defender wins.
    \end{enumerate}
\end{definition}

\begin{definition}
    Two labeled transition systems \IS and \IT are \emph{bisimilar} if
    the \Defender has a winning strategy in the Ehrenfreucht-Fraïssé game
    with \IS and \IT.
\end{definition}

\begin{example}
    The two transition systems below, with one edge label that we represent by a simple arrow,
    and vertice labels $\set{P}$ that we write on the node, next to the name of the node (which is only used for clarity, states in transition systems are not named, and thus cannot be distinguished by the names.), are bissimilar:

    \begin{center}
    \begin{tikzpicture}[automata]
        \node[state] (X) at (-5, 0) {$\alpha \Forces$};
        \node[state, below of=X] (Y) {$\beta \Forces P$};
        \draw (X) edge (Y)
                  edge[loop above] (X);

        \node[state] (A) {$\gamma \Forces$};
        \node[state] (B) at (-1, -2) {$\delta \Forces P$};
        \node[state] (C) at (1, -2) {$\eta \Forces P$};
        \draw (A) edge (B)
                  edge (C)
                  edge[loop above] (X);
    \end{tikzpicture}
    \end{center}

    Indeed, we can exhibit a winning strategy for the \Defender:
    \begin{itemize}
        \item If the \Attacker starts with $\beta$, the \Defender
            can pick $\delta$, which has the same labels.
            On the second turn, the \Attacker needs to choose
            one of the two previous nodes, $\beta$ or $\delta$
            and a transition out of it. Since no transition leaves either node,
            she cannot play and loses.
        \item Similarly, if the \Attacker starts with $\delta$ or $\eta$, the \Defender
            can pick $\beta$, and the \Attacker is not able to play in the next round.
        \item If the \Attacker picks $\alpha$ or $\gamma$,
            the \Defender can answer respectively with $\y$ or $\alpha$,
            since it also has the same labels. On the next turn,
            \begin{itemize}
                \item if the \Attacker
                    picks the first model and $\beta$, the \Defender can pick $\delta$
                    in the second model, and wins for the same reason as in the first case.
                \item if she picks the second model and either $\delta$ or $\eta$,
                    the \Defender can pick $\beta$ in the first model, the \Attacker will not be able to play
                    in the next turn.
                \item if she picks either $\alpha$ or $\gamma$,
                    the \Defender picks the other one, and the game is back to the same
                    state as the first turn.
                    Since all other moves of the \Attacker are immediately loosing,
                    she might play either $\alpha$ or \y infinitely many times,
                    which gives the victory to the \Defender, because the \Attacker
                    fails to reveal any difference between the two models.
            \end{itemize}
    \end{itemize}

    In this example, we can feel why the two models are bisimilar: however
    the \Attacker moves in either graph, we can always move in a symmetrical fashion in
    the other graph.

    We can also notice that at any point in a game, the winner does not depend on the history of the game,
    but only on the two positions picked at the last turn.
    This kind of game is called memoryless because there is always a winning strategy
    that depends only on the last move.
\end{example}

\begin{example}
    The two transition systems below are bissimilar:
    \begin{center}
        \begin{tikzpicture}[automata]
           \node[state] (A) {$\alpha \Forces P$};
           \node[state, right of=A] (B) {$\beta \Forces Q$};
           \draw (A) edge[bend left] (B);
           \draw (B) edge[bend left] (A);
        \end{tikzpicture}
    \end{center}

    \begin{center}
        \begin{tikzpicture}[automata]
            \node[state] (A) {$1 \Forces P$};
            \node[state, right of=A] (B) {$2 \Forces Q$} edge[<-] (A);
            \node[state, right of=B] (C) {$3 \Forces P$} edge[<-] (B);
            \node[state, right of=C] (D) {$4 \Forces Q$} edge[<-] (C);
            \node[state, right of=D] (E) {$5 \Forces P$} edge[<-] (D);
            \node[right of=E] {\dots} edge[<-] (E);
        \end{tikzpicture}
    \end{center}
\end{example}

\begin{example}
    Those two transition systems are not bissimilar:
    \begin{center}
        \begin{tikzpicture}[automata]
            \node[state] (A) {$1 \Forces \phantom{P}$};
            \node[state, right of=A] (B) {$2 \Forces P$} edge[<-] (A);
            \node[state, right of=B] (C) {$3 \Forces \phantom{P}$} edge[<-] (B);
        \end{tikzpicture}
        \quad\quad
        \quad\quad
        \begin{tikzpicture}[automata]
            \node[state] (A) {$\alpha \Forces \phantom{P}$};
            \node[state, right of=A] (B) {$\beta \Forces P$} edge[<-] (A);
        \end{tikzpicture}
    \end{center}

    Indeed, the \Attacker has a winning strategy:
    \begin{itemize}
        \item On the first turn, the \Attacker picks state 3 in the left model.
        \item The \Defender is forced to pick $\alpha$ since it is the
            only state with an empty label in the right model.
        \item On the second turn, the \Attacker can pick either $3$ or $\alpha$
            but since 3 has no outgoing transition, she picks $\alpha$
            and the \Defender cannot pick any transition in the left model
            and looses.
    \end{itemize}
\end{example}


\section{Mu calculus}

\subsection{A strange logic}

We have seen the notion of bisimilarity, which is one way of considering
different models the same. However, in MSO, there are formulas
that do not have the same truth value in two bisimilar models
One example is the formula $\phi$ saying that there are two states that with label $P$,
which is true in the second model but not the first:
\[
    \phi := \exists x~ \exists y~ P(x) \wedge P(y) \wedge \neg (x = y)
\]
    \begin{center}
    \begin{tikzpicture}[automata]
        \node[state] (X) at (-5, 0) {};
        \node[state, below of=X] (Y) {$P$};
        \draw (X) edge (Y)
                  edge[loop above] (X);

        \node[state] (A) {};
        \node[state] (B) at (-1, -2) {$P$};
        \node[state] (C) at (1, -2) {$P$};
        \draw (A) edge (B)
                  edge (C)
                  edge[loop above] (X);
    \end{tikzpicture}
    \end{center}


On the other hand, some formulas always
have the same truth value in bisimilar models.
If one is to study which formulas of MSO are invariant under bisimilarity,
they find a class of formulas that corresponds to the $\mu$-calculus.

The $\mu$-calculus is an extension of propositional logic,
extended with modal and fixpoint operators.

\begin{definition}
    The \emph{signature} of a $\mu$-calculus language is
    $\sigma = P \cup M$, where
    \begin{itemize}
        \item $P$ contains propositional symbols of arity 0.
        \item $M$ contains modal operators symbols.
    \end{itemize}
    Both of those sets can be finite or infinite.
\end{definition}

\begin{definition}
    The \emph{formulas} of the $\mu$-calculus with signature $\sigma = P \cup M$
    is the smallest set such that:
    \begin{itemize}
        \item each proposition $p \in P$ and each variable is a formula.
        \item if $\phi$ and $\psi$ are formulas, then $\phi \wedge \psi$ is a formula.
        \item if $\phi$ is a formula, then $\neg \phi$ is a formula.
        \item for each modal operator $m \in M$, and formula $\phi$,
            $\boite{m} \phi$ is a formula read ``$m$ box $\phi$''.
        \item if $Z$ is a variable and $\phi$ a formula,
            and every occurence of $Z$ occurs positively in $\phi$,
            that is, is under an even number of negations,
            then $\nu Z\, \phi$ is a formula.
    \end{itemize}
    Furthermore, if $\phi, \psi$ are formulas, $m$ is a modal operator
    and $Z$ is a variable, we have the following shorthands:
    \begin{itemize}
        \item $\phi \vee \psi$ stands for $\neg (\neg \phi \wedge \neg \psi)$
        \item $\diam m \phi$ stands for $\neg \boite m \neg\phi$. This is read ``$a$ diamond $\phi$''.
        \item $\mu Z\, \phi$ stands for $\neg \nu Z\, \neg\phi[Z := \neg Z]$.
            where $\phi[Z := \neg Z]$ is the formula obtained by replacing
            every occurence of $Z$ by $\neg Z$ in $\phi$.
    \end{itemize}
\end{definition}


\begin{definition}
    A \emph{model} of $\mu$-calculus with signature $\sigma = P \cup M$
    is a \emph{labeled transition system}
    $\IS = (S, \Lambda, \Gamma, R, V)$, where:
    \begin{itemize}
        \item $S$ is the set of states.
        \item $\Lambda = M$ is the set of edge labels, or modal operators.
        \item $\Gamma = P$ is the set of state labels, or propositional symbols.
        \item $R: M \to \Pp(S \times S)$ maps each
            modal operators to a binary relation on states.
            This can be seen as $\abs M$ directed graphs.
        \item $V: P \to \Pp(S)$ maps each propositional symbol to
            the set of states on which it is true.
    \end{itemize}
    Since $\Lambda = P$ and $\Gamma = M$ are part of the signature of the
    language, we will not write them explicitly and introduce
    labeled transition systems as $\IS = (S, R, V)$.
\end{definition}

Finally, we need to describe how $\mu$-calculus
formulas are interpreted in a given labelled transition system.
Four facts differ from classical propositional
logic:
\begin{itemize}
    \item The meaning of a formula is the set of states on which it is true.
        In particular, a formula does not have a truth value in a given model,
        but only at a given state in the model.
    \item The modal operators $\boite m$ and $\diam m$ correspond
        to movements in the directed graph corresponding to $m$.
        The box operator $\boite m \phi$ means that $\phi$ is satisfied in
        every $m$-neighbour of the current state. On the other hand,
        the diamond operator $\diam m \phi$ means that there exists
        a $m$-neighbour in which $\phi$ is satisfied.
    \item Variables are not interpreted as states, but as sets of states
        on which they are true.
    \item The fixpoint operator $\mu$ is the least fixpoint
        whereas $\nu$ is the greatest fixpoint in the sense
        that $\nu Z \, \phi$ is true in the largest set of states $Z$
        such that $\phi$ is satisfied on $Z$.
\end{itemize}

\begin{definition}
    Let $\IS = (S, R, V)$ be a labeled transition system with signature $\sigma = P \cup M$.
    An interpretation $i$ is a map that associates each variable $Z$
    to the set of states $i(Z) \subseteq S$ on which it is true.

    The \emph{meaning} of a formula $\phi$ is the set of states $\Meaning{\phi}^\IS_i \subseteq S$
    defined as follows.
    \begin{itemize}
        \item $\Meaning{p}^\IS_i = V(p)$ if $p \in P$.
        \item $\Meaning{Z}^\IS_i = i(Z)$ if $Z$ is a variable.
        \item $\Meaning{\phi \wedge \psi}^\IS_i = \Meaning{\phi}^\IS_i \cap \Meaning{\psi}^\IS_i$
            if $\phi, \psi$ are formulas.
        \item $\Meaning{\neg \phi}^\IS_i = S \setminus \Meaning{\phi}^\IS_i$
            if $\phi$ is a formula.
        \item $\Meaning{\boite m \phi}^\IS_i = \setst{s \in S}{
            \forall t \in S~ (s, t) \in R(m) \implies t \in \Meaning{\phi}^\IS_i}$
            if $\phi$ is a formula and $m$ a modal operator.
        \item $\Meaning{\nu Z \, \phi}^\IS_i = \bigcup \setst{T \subseteq S}{T \subseteq \Meaning{\phi}^\IS_{i[Z := T]}}$
            if $\phi$ is a formula. Where $i[Z := T]$ maps $Z$ to $T$ and the rest of the map $i$ is not modifed.
    \end{itemize}
    If follows that the interpretations of $\vee$, $\diam{m}$ and $\mu$
    are, $\phi, \psi$ are formulas:
    \begin{itemize}
        \item $\Meaning{\vee \phi \wedge \psi}^\IS_i = \Meaning{\phi}^\IS_i \cup \Meaning{\psi}^\IS_i$.
        \item $\Meaning{\diam m \phi}^\IS_i = \setst{s \in S}{\exists t \in S~ (s, t) \in R(m) \implies t \in \Meaning{\phi}^\IS_i}$
        \item $\Meaning{\mu Z\, \phi}^\IS_i = \bigcap \setst{T \subseteq S}{\Meaning{\phi}^\IS_{i[Z := T]} \subseteq T}$
    \end{itemize}
\end{definition}

Informally, we have that
\begin{itemize}
    \item $p$ holds for all states in $V(p)$
    \item $Z$ holds for all states in $i(Z)$
    \item $\phi \wedge \psi$ holds for states where both $\phi$ and $\psi$ hold.
    \item $\phi \vee \psi$ holds for states where either $\phi$ or $\psi$ hold.
    \item $\neg \phi$ holds for states where $\phi$ doesn't hold.
    \item $\boite m \phi$ holds in $s$ if all $m$-transitions from $s$ lead to states where $\phi$ holds.
    \item $\diam m \phi$ holds in $s$ if there exists a $m$-transition from $s$ to a state where $\phi$ holds.
    \item $\nu Z \, \phi$ holds in a state $s$
        if there exist a subset $T \subseteq S$ of states
        that contains $s$ and when $Z$ is interpreted as $T$
        in $\phi$, the set on which $\phi$ holds contains $T$.

        Note that the application
        $\Meaning{\phi}^\IS_{i[Z := T]}$ is increasing in $T$,
        because every syntactic construction but the negation are clearly
        increasing functions of $T$, and the negation is a decreasing
        function. Nevertheless, the variable $Z$ is always under an even number of
        negation, therefore by composition of decreasing function,
        $\Meaning{\phi}^\IS_{i[Z := T]}$ is increasing in $T$.

        By Knaster-Tarski's theorem, $\Meaning{\nu Z\, \phi}^\IS_i$
        is then the largerst fixed point of $\Meaning{\phi}^\IS_{i[Z := T]}$.
    \item On the other hand, $\mu Z \, \phi$ is the smallest fixed point
        of $\Meaning{\phi}^\IS_{i[Z := T]}$.
\end{itemize}

We give a few examples of formulas and their meanings but without detailed
explanations, as the semantics defined above are concise, but hard to interpret.
In fact, we give an other caraterisation of the meaning of formulas using games,
which makes reasonning with $\mu$-calculus easier.

\begin{example}
    We adopt the convention that when a language has only
    one modal operator, for instance $\boite{m}$ and $\diam{m}$,
    we write them simply as $\boite{}$ and $\diam{}$ respectively.
    Let $\phi$ any formula of the $\mu$-calculus, (for instance, a proposition):
    \begin{itemize}
        \item $\nu Z \Par{\phi \wedge \boite{} Z}$ is interpreted
            as ``\phi is true along every path''.
            Indeed, $Z$ is the largest set of states in which $\phi$ is true,
            and which remains true after moving along any edge.
        \item $\mu Z \Par{\phi \vee \diam{} Z}$ is interpreted
            as the existence of a path leading to a node where $\phi$ holds.
        \item $\nu Y~ \mu X~ (\p \wedge \diam{} Y) \vee \diam{} X$
            is the largest set of nodes which is closed under the property
            that there is a path leading to a node where $\p$ holds.
            Said otherwise, it is the set of paths on which \p holds inifinitely many times.
    \end{itemize}
\end{example}

% \subsection{Relation to MSO}

\todo{todo be do}

\subsection{Model checking}

As is often the case in logic,
the semantics of $\mu$-calculus can
be defined alternatively defined via a two player game
between the \Verifier and \Falsifier.

% To that extent, we need to define the alternating depth
% of a $\mu$-calculus variable and the concept of parity games.

% \begin{definition}
% Let $\phi$ be a formula of $\mu$-calculus.
% The \emph{alternating depth} of $\phi$, $\AlternatingDepth(\phi)$
% is the greatest number of syntactical alternations between least and greatest
% fixpoint operators. That is, if $\phi$ is considered as a syntactic tree,
% it is the largest number of alternations present on a single branch.

% If there are no alternations, the depth is zero.
% \end{definition}

% \begin{example}
%     In a language with a $p$ as propositional symbol, we have that:
% \begin{itemize}
%     \item $p \wedge \diam{}q$ has alternating depth 0
%     \item $\mu X~ p \vee \boite{} X$ also has alternating depth 0
%     \item $\nu Y~ \mu X~ (p \wedge \diam{} Y) \vee \diam{} X$ has alternating depth 2
%     \item $\mu X \parenthesis{p \wedge \nu Y (p \vee Y) \wedge \mu Z (X \vee Z)}$ has alternating
%         depth 2, because of the branch with $X$ and $Y$.
% \end{itemize}
% \end{example}

To that extent, we need to define parity games.

Parity games are an important subject in complexity theory,
as the problem of deciding whether the first or second player
has a winning strategy is one of the few problems we know is
in $\NP \cap \coNP$ be don't know if it is in $\Ptime$.
Finding the best bounds for the complexity of this problem is
an active field of reasearch, with the first
quasipolynomial time algorithm, due to \cite{calude2017deciding}.
There have been many variants of this algorithm since and it is still
an open question to understand them well and know whether a better algorithm
can be devised.
Lastly, this problem is one of the few problems in $\mathsf{UP} \cap \mathsf{coUP}$
that are not found to be in $\Ptime$ yet \cite{jurdzinski1998deciding}.
The most famous problem that fit in this category was primality checking.

As a reminder, the class $\mathsf{UP}$ is the class of decision problems
that can be verified in polynomial time and have unique short certificates,
that is, there is a polynomial Turing machine in which at most one computation path accepts.

This makes $\mu$-calculus a good logic with both a good expressivity and
good algorithmic properties, as its model checking is based on parity games.

\begin{definition}
    The \emph{parity game} is an inifinite two player game
    played on a directed graph $G = (V, E)$. Let $V_0, V_1$
    be a partition of the vertices of $G$, and $p: V \to \N$
    any function, called the \emph{priority function}.
    Let also $v_0 \in V$ be the starting point of the game.

    The game goes as follows:
    \begin{itemize}
        \item It starts at $v_0$
        \item At a given turn $i$, if $v_i \in V_0$,
            player 0 decides to move to an adjacent node
            $v_{i+1}$. Otherwise if $v_i \in V_1$, it is
            player 1 that picks a neighbour of $v_i$.
        \item If a player cannot pick a neighbour,
        \item After \w turns, they have produced an infinite sequence of vertices
            $(v_n)_{n \in \N} \in V$.
            The least priority that was seen infinitely many
            times determines the winner,  player$\max \setst{p(v)}{v \in \Inf(v)}$ is even, player 0
            wins. If it is odd, player 1 wins.
    \end{itemize}
\end{definition}

Note that any parity game is determined, as the winning set is
\[
    W = \setst{b \in T}{
        \exists z \in V ~ \forall z' \in V \left(
            \begin{array}{c}
                p(z) \even
                \\ \wedge \\
                \existsinf i,~ v_i = z
                \\ \wedge \\
                p(z') > p(z) \implies \exists N \forall n > N v_n \neq z'
            \end{array}
        \right)
    }
\]
which is a Borel set (in fact, it is $\borelsigma{3}$).
Since all Borel games are determinated \cite{martin1975borel} there is always
a player that has a winning strategy.

We give an example of the model-checking game of $\mu$-calculus
before defining it.
Let $\phi = \nu Y~ \mu X~ (p \wedge \diam{} Y) \vee \diam{} X$ be a formula
and we want to know whether some model satifies it.
We first draw the formula as a tree:
\begin{center}
    \begin{tikzpicture}[automata,every node/.style={circle,draw}]
        \node (1) {$\nu Y$};
        \node[below of=1] (2) {$\mu X$} edge[<-] (1);
        \node[below of=2] (3) {$\vee$} edge[<-] (2);
        \node[right of=3] (4) {$\diam{}$} edge[<-] (3);
        \node[below of=4] (5) {$X$} edge[<-] (4);
        \node[left of=3] (6) {$\wedge$} edge[<-] (3);
        \node[left of=6] (7) {$p$} edge[<-] (6);
        \node[below of=6] (8) {$\diam{}$} edge[<-] (6);
        \node[below of=8] (9) {$Y$} edge[<-] (8);
    \end{tikzpicture}
\end{center}

And then we connect each variable to the node where it is bound.
With some rearanging of the nodes for clarity and removing the variable names
as they will not be used anymore, we get:

\begin{center}
    \begin{tikzpicture}[automata,every node/.style={circle,draw}]
        \node (1) {$\nu$};
        \node[below of=1] (2) {$\mu$} edge[<-] (1);
        \node[below of=2] (3) {$\vee$} edge[<-] (2);
        \node[right of=3] (4) {$\diam{}$} edge[<-] (3)
                                          edge[->] (2);
        \node[left of=3] (6) {$\wedge$} edge[<-] (3);
        \node[below of=6] (7) {$p$} edge[<-] (6);
        \node[above of=6] (8) {$\diam{}$} edge[<-] (6)
                                          edge[->] (1);
    \end{tikzpicture}
\end{center}

We then assign a priority to each node depending on their position in the formula $\phi$:
\begin{itemize}
    \item Every greatest fixpoint operator $\nu$ is assigned an even number,
        greater than the priority of every least fixpoint operator $\mu$
        above it in the tree of the formula.
        Here the $\nu$ has no $\mu$ above it, so we can give it
        a priority of $0$.
    \item Conversely, every least fixpoint operator $\mu$ is assigned an odd number,
        larger than the priority of every greatest fixpoint operator $\nu$
        above it in the tree of the formula.
        Here $\mu$ has a $\nu$ of priority 0 in the formula above it
        so we can give it priority 1.
    \item Every non-fixpoint node gets an odd priority, higher than every other priority.
        In this example, we can assign $3$ to each other node, but for clarity
        we will not draw them on the graph.
\end{itemize}

\begin{center}
    \begin{tikzpicture}[automata,every node/.style={circle,draw}]
        \node (1) {$\nu$};
        \node[below of=1] (2) {$\mu$} edge[<-] (1);
        \node[below of=2] (3) {$\vee$} edge[<-] (2);
        \node[right of=3] (4) {$\diam{}$} edge[<-] (3)
                                          edge[->] (2);
        \node[left of=3] (6) {$\wedge$} edge[<-] (3);
        \node[below of=6] (7) {$p$} edge[<-] (6);
        \node[above of=6] (8) {$\diam{}$} edge[<-] (6)
                                          edge[->] (1);

        \node[priority even] at ($(1.north east) + (0.07, 0.07)$) {0};
        \node[priority odd]  at ($(2.north east) + (0.07, 0.07)$) {1};
    \end{tikzpicture}
\end{center}

The formula consists of half of the game,
indeed, it needs to be checked against a model.
Given a model $\IS = (S, R, V)$ and a state $s \in S$,
we want to know whether $\phi$ holds at $s$.
For the first example, we take as model an infinite binary
tree with no node satisfying the property $p$, that is $V(p) = \emptyset$.

\begin{center}
    \begin{forest}for tree={circle,draw,minimum size=0.5cm,edge={->}},where level=0{}{if level=4{draw=none,rectangle}{}},
        [
            [[[[\dots] [\dots]] [[\dots] [\dots]]] [[[\dots] [\dots]] [[\dots] [\dots]]]]
            [[[[\dots] [\dots]] [[\dots] [\dots]]] [[[\dots] [\dots]] [[\dots] [\dots]]]]
        ]
    \end{forest}
\end{center}

The game is played both in the formula and the model
at the same time. Each turn, one of the two players decides
where to move in both structures.
The game starts at the root of the formula and the state $s_0$
in the model.
The person that plays and their allowed moves are given by
the current node of the formula. At each turn, the current player
must move in the tree of the formula to a neighbouring node,
and potentially also make an extra action.

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Formula node & Player & Action \\
        \hline
        \hline
        $p$ &       & End of the game
        \\\hline
        $\vee$ & Player 0 &
        \\\hline
        $\wedge$ & Player 1 &
        \\\hline
        $\diam{}$ & Player 0 & Pick $s_{n+1} \in S \st s_n \to s_{n+1}$
        \\\hline
        $\boite{}$ & Player 1 & Pick $s_{n+1} \in S \st s_n \to s_{n+1}$
        \\\hline
        $\neg$ & Any, there is only one choice & Player 0 and 1 switch roles
        \\\hline
        $\mu$ & Any, there is only one choice &
        \\\hline
        $\nu$ & Any, there is only one choice &
        \\\hline
    \end{tabular}
\end{center}

If the game ends on a proposition (after a finite number of turns),
the winner is Player 0 if the last visited state in the model
satisfies the proposition, otherwise, Player 1 wins.
If the game runs for \w turns, the winner is determined by
the smallest priority that was visited infinitely many times.

In the current example, the position in the model does not matter much,
because every state looks like any other (formally, there is a bisimilarity relation
between any two states). We can therefore focus on what happens in the graph of the formula.

The game starts on \State{\nu}, and since there is only one choice,
proceeds to \State{\mu}. On the next turn, there is still only one choice,
so the game proceeds to the \State{\vee} node.
On the \State{\vee} node, it is Player 0, also known as the Verifier that has to play.
She can choose to move either to the \State{\diam{}} node on the right or the \State{\wedge}
node. We examine both cases:
\begin{itemize}
    \item If she picks \State{\wedge} it is then Player 1's turn to play
        and we can chose between the node \State{p} and the node \State{\diam{}} above.
        However, moving to the node \State{p} is a winning move for him!
        Indeed, because they have reached a proposition symbol,
        the game ends and Player 1 wins if the current state in the model
        does not satisfy the proposition $p$. But since no state in the model
        satisfies $p$, he surely wins.
    \item On the other hand, if she picks \State{\diam{}} it is again Player 0's turn.
        For this turn, she needs takes two actions, she first moves to
        the only neighbour of \State{\diam{}} which is \State{\mu} and picks $s_1 \in S$, a neighbour
        of $s_0$.
        From \State{\mu} the game proceeds to the node \State{\vee} and the same choice
        is offered to Player 0.
\end{itemize}

So if Player 0 decides to move to \State{\wedge}, she looses. On the other hand,
if she always decides to move to \State{\diam{}},
the infinite path built by the two player is
$\State{\nu}, \State{\mu}, \State{\vee}, \State{\diam{}}, \State{\mu}, \dots$,
as shown in orange below.

\begin{center}
    \begin{tikzpicture}[automata,every node/.style={circle,draw}]
        \node (1) {$\nu$};
        \node[below of=1] (2) {$\mu$} edge[<-,very thick,atomictangerine] (1);
        \node[below of=2] (3) {$\vee$} edge[<-,very thick,atomictangerine] (2);
        \node[right of=3] (4) {$\diam{}$} edge[<-,very thick,atomictangerine] (3)
                                          edge[->,very thick,atomictangerine] (2);
        \node[left of=3] (6) {$\wedge$} edge[<-] (3);
        \node[below of=6] (7) {$p$} edge[<-] (6);
        \node[above of=6] (8) {$\diam{}$} edge[<-] (6)
                                          edge[->] (1);

        \node[priority even] at ($(1.north east) + (0.07, 0.07)$) {0};
        \node[priority odd]  at ($(2.north east) + (0.07, 0.07)$) {1};
    \end{tikzpicture}
\end{center}

Here, the set of states visited infinitely many times is then
$\set{\State{\mu}, \State{\vee}, \State{\diam{}}}$
and the minimum priority is $\min \set{1, 3, 3} = 1$ and Player 0 loses.
Indeed, the run passes infinitely many times by the $\mu$ of priority
1, but only finitely many times through the $\nu$ of priority 0 (in fact, only once).

We have shown here that there is a winning strategy for Player 1, regardless
of the starting node $s \in S$, the formula $\phi$ holds nowhere in this model.

\paragraph*{}
To understand what $\phi$ does, we look at the game with a model in which it is verified.
This model is the infinite binary tree on which every second node on the leftmost
branch satisfy the property $p$:

\begin{center}
    \begin{forest}for tree={circle,draw,minimum size=0.5cm,edge={->}},where level=0{}{if level=4{draw=none,rectangle}{}},
        [
            [p [[p[\dots] [\dots]] [[\dots] [\dots]]] [[[\dots] [\dots]] [[\dots] [\dots]]]]
            [[[[\dots] [\dots]] [[\dots] [\dots]]] [[[\dots] [\dots]] [[\dots] [\dots]]]]
        ]
    \end{forest}
\end{center}

The difference with the previous example is that now, Player 0
can sometimes choose to move to the node \State{\wedge}
without directly losing in the next turn.
Indeed, if she chooses to move to \State{\wedge}
from \State\vee when the current position in the model satisfies $p$,
Player 1 will not move to the node \State p as he would directly lose.
Instead, a wise choice is to move up to \State{\diam{}}.
From there, it is up to Player 0 to choose where to move inside the model
before reaching the initial state \State\nu in the formula.

If Player 0 somehow manages to do this loop infinitely many,
they will have visited \State\nu of priority 0 infinitely many times
and she would win.
She can do this if and only if the run inside the model visits infinitely many
times a node with $p$, so that she can decide to go to the loop on the left of the
formula (according to the chosen layout of the graph).

If the run starts on the leftmost branch, her strategy is then deceptively simple,
as it is always her that chooses where to move in the model (there are no box operators in the formula),
which just stays in the leftmost branch. Every time she reaches \State\vee,
if the current node has label $p$, she decides to take the left loop in
the formula, otherwise she takes the left loop.
In the model given in the example, she would alternate between the left and right loop,
as every second state has the label $p$. However, in a more general setting,
she could wait as long as she wants on the right loop, waiting for a state
with $p$ and then take the left loop.

Even if this might not be obvious at first sight,
this means that $\phi$ is valid in every node
from which there exists
a path that visits infinitely many times a node with label $p$.



\begin{definition}
    Let $\phi$ be a formula of $\mu$-calculus,
    $\IS = (S, R, V)$ be a model and $s_0 \in S$ a starting state.
    The \emph{model checking game} of $\phi$ on $(\IS, s_0)$
    is a parity game as follows.

    \paragraph{Vertices}
    The game starts at $(\phi, s_0)$.
    At each turn, the two players play
    both a subformula of $\phi$ and a node $s_i \in S$.
    If we denote the set of subformulas of $\phi$ by $\Phi$,
    the vertices of the graph is thus $\Vv = \Phi \times S$.

    \paragraph{Edges}
    A node $(\psi, s) \in \Vv$ is connected to other nodes depending
    on the type of $\psi$.
    and if $Z$ is a variable in $\phi$, we write $\phi_Z \in \Phi$ for the
    subformula of $\phi$ that binds $Z$. The edges of the graph are given as follows:

    \begin{center}
    {\renewcommand{\arraystretch}{1.5}
    \begin{tabular}{|c|c|c|}
        \hline
        $\psi$ & Neighbours of $(\psi, s)$ & Partition
        \\\hline\hline
        Atomic propositon $p$ & $\emptyset$ & $\begin{cases}
            1 - N & \tif s \in V(p) \\
            N & \otherwise
        \end{cases}$
        \\\hline
        Variable $Z$ & $\set{(\phi_Z, s)}$ & 0
        \\\hline
        $\neg \psi'$ & $\set{(\psi', s)}$ & 0
        \\\hline
        $\psi_0 \vee \psi_1$ & $\set{(\psi_0, s), (\psi_1, s)}$ & N
        \\\hline
        $\psi_0 \wedge \psi_1$ & $\set{(\psi_0, s), (\psi_1, s)}$ & 1 - N
        \\\hline
        $\diam{m} \psi'$ & $\setst{(\psi', t)}{t \in \Neigh[m]{\IS}{s}}$ & N
        \\\hline
        $\boite{m} \psi'$ & $\setst{(\psi', t)}{t \in \Neigh[m]{\IS}{s}}$ & 1 - N
        \\\hline
        $\mu Z~ \psi'$ & $\set{(\psi', s)}$ & 0
        \\\hline
        $\nu Z~ \psi'$ & $\set{(\psi', s)}$ & 0
        \\\hline
    \end{tabular}
    }
    \end{center}

    \paragraph{Partition}
    The last column of the table discribes the partition, $V_0$ or $V_1$
    in which the node $(\psi, s)$ belongs. This partition depends on whether
    there is an even number of negations above $\psi$ in $\phi$ or an odd number.
    We denoted by $N \in \set{0, 1}$ the parity of the number of negations,
    so that if a node in the partition $N$ is under an even number of negations,
    it is in $V_0$ and otherwise in $V_1$, and conversly for $1 -N$.
    When there is only one neighbour in the graph, it doesn't matter who plays,
    so we arbitrarily put all those nodes in $V_0$.

    This formalises the fact that the two players switch roles when encountering
    a negation.
    Note that there is no problem with loops in the graph, as the only loops
    are made by variables, which are always under an even number of negations.

    For atomic propositions, the game ends and we want the winner to be Player 0 if $p$ holds at $s$,
    except if $p$ is negated (or under an odd number of negations), in which case the winner is Player 1.

    \paragraph{Priorities}
    To define the priority function $p: \Vv \to \N$
    we need an auxilary function $h: \Phi \to \N$ defined
    recursively from the root of $\phi$ and downward to each subformula $\psi$.
    Given $\psi \in \Phi$, we write $\psi^\wedge$ for the set of all formulas that contain strictly $\psi$.
    We define $h$ as follows:
    \begin{itemize}
        \item If $\psi$ is a $\mu$-formula or $\nu$-formula, that is, a formula with the
            operator $\mu$ (resp. $\nu$) at the root and $\phi^\wedge$ contains no fixpoint operator.
            Then \[
                h(\psi) = \begin{cases}
                    0 & \tif \psi \text{ is a $\nu$ formula} \\
                    1 & \tif \psi \text{ is a $\mu$ formula} \\
                \end{cases}
            \]
        \item If $\psi$ is a $\mu$-formula (ie. a formula with the operator $\mu$ at the root),
        then \[
            h(\psi) := 1 + \max \setst{p(\chi)}{\chi \in \psi^\wedge \wedge \chi \text{ is a $\nu$ formula}}
        \]
        \item If $\psi$ is a $\nu$-formula,
        then \[
            h(\psi) := 1 + \max \setst{p(\chi)}{\chi \in \psi^\wedge \wedge \chi \text{ is a $\mu$ formula}}
        \]
        \item Otherwise $h(\phi)$ is any number larger that every value given to $\mu$ and $\nu$
        formulas, for instance, the size of the whole formula $h(\psi) := \abs{\phi}$
    \end{itemize}
    We then simply define $p(\psi, s) := h(\psi)$.

\end{definition}

\todo{Add a conclusion, don't end with a definition!}













\clearpage
\appendix
\section{Computing the Safra construction}

This appendix contains the Python code that was developped to convert
any Büchi automaton into a Muller automaton.
The code runs in any linux environement where its three dependencies are installed:
\begin{itemize}
    \item The Graphviz software, used to layout and draw graphs: \url{https://www.graphviz.org/}
    \item Python 3.9 (or higher): \url{https://www.python.org/}
    \item The python packages \texttt{click} (for the command line interface) and \texttt{dot2tex} (conversion of Graphviz output to \LaTeX{})
        which are available on PyPI
        and can be installed with \texttt{pip install click dot2tex}.
\end{itemize}

This code can be run with \texttt{python safra.py --help} to get a list of the available options
and usage examples. Because scripts and software are living beings, a more up-to-date
version can be found at \url{https://gitlab.com/ddorn/safra}.

\usemintedstyle{friendly}
\inputminted[fontsize=\tiny]{python}{./safra_for_tex.py}


\newpage
\nocite{*}
\bibliographystyle{apalike}
\bibliography{bibliography.bib}

\end{document}